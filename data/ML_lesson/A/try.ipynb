{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-06T02:11:28.711216Z",
     "start_time": "2025-11-06T02:11:17.978932Z"
    }
   },
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, MultiHeadAttention, Dropout, GRU, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "import akshare as ak\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # ä½¿ç”¨é»‘ä½“\n",
    "plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜\n",
    "plt.rcParams['font.size'] = 12  # è®¾ç½®å­—ä½“å¤§å°\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®é¡µé¢é…ç½®\n",
    "st.set_page_config(\n",
    "    page_title=\"æ™ºèƒ½è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ\",\n",
    "    page_icon=\"ğŸ“ˆ\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "\n",
    "# é…ç½®akshareçš„è¯·æ±‚ä¼šè¯ï¼Œæ·»åŠ é‡è¯•æœºåˆ¶å’Œå»¶è¿Ÿ\n",
    "def create_session():\n",
    "    session = requests.Session()\n",
    "\n",
    "    # è®¾ç½®é‡è¯•ç­–ç•¥\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\"],\n",
    "        backoff_factor=1\n",
    "    )\n",
    "\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    # è®¾ç½®éšæœºUser-Agent\n",
    "    user_agents = [\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'\n",
    "    ]\n",
    "\n",
    "    session.headers.update({\n",
    "        'User-Agent': random.choice(user_agents),\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "    })\n",
    "\n",
    "    return session\n",
    "\n",
    "\n",
    "# å…¨å±€ä¼šè¯å¯¹è±¡\n",
    "if 'ak_session' not in st.session_state:\n",
    "    st.session_state.ak_session = create_session()\n",
    "\n",
    "\n",
    "class TrainingProgressCallback(Callback):\n",
    "    \"\"\"è‡ªå®šä¹‰å›è°ƒå‡½æ•°ç”¨äºæ˜¾ç¤ºè®­ç»ƒè¿›åº¦\"\"\"\n",
    "\n",
    "    def __init__(self, progress_bar, status_text, epochs):\n",
    "        self.progress_bar = progress_bar\n",
    "        self.status_text = status_text\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        progress = (epoch + 1) / self.epochs\n",
    "        self.progress_bar.progress(progress)\n",
    "        self.status_text.text(\n",
    "            f\"è®­ç»ƒè¿›åº¦: {epoch + 1}/{self.epochs} - æŸå¤±: {logs['loss']:.4f}, éªŒè¯æŸå¤±: {logs['val_loss']:.4f}\")\n",
    "\n",
    "\n",
    "class StockPredictor:\n",
    "    def __init__(self, time_window=30):\n",
    "        self.time_window = time_window\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        self.model = None\n",
    "        self.features = [\"å¼€ç›˜\", \"æœ€é«˜\", \"æœ€ä½\", \"æ”¶ç›˜\", \"æˆäº¤é‡\"]\n",
    "        self.close_idx = self.features.index(\"æ”¶ç›˜\")\n",
    "        self.is_trained = False\n",
    "        self.model_type = \"LSTM+Attention\"\n",
    "        self.data_cache_dir = \"stock_data_cache\"\n",
    "\n",
    "    def get_stock_data(self, stock_code, start_date=\"20200101\", end_date=None):\n",
    "        \"\"\"è·å–è‚¡ç¥¨æ•°æ® - å¸¦æœ‰ç¼“å­˜å’Œæ›´æ–°æœºåˆ¶\"\"\"\n",
    "        if end_date is None:\n",
    "            end_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "        # åˆ›å»ºç¼“å­˜ç›®å½•\n",
    "        os.makedirs(self.data_cache_dir, exist_ok=True)\n",
    "\n",
    "        # ç¼“å­˜æ–‡ä»¶è·¯å¾„\n",
    "        cache_file = os.path.join(self.data_cache_dir, f\"{stock_code}.pkl\")\n",
    "\n",
    "        # å°è¯•ä»ç¼“å­˜åŠ è½½æ•°æ®\n",
    "        cached_data = None\n",
    "        if os.path.exists(cache_file):\n",
    "            try:\n",
    "                with open(cache_file, 'rb') as f:\n",
    "                    cached_data = pickle.load(f)\n",
    "                st.info(f\"ä»ç¼“å­˜åŠ è½½è‚¡ç¥¨ {stock_code} æ•°æ®\")\n",
    "            except Exception as e:\n",
    "                st.warning(f\"åŠ è½½ç¼“å­˜æ•°æ®å¤±è´¥: {e}\")\n",
    "\n",
    "        # å¦‚æœæœ‰ç¼“å­˜æ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°\n",
    "        if cached_data is not None and not cached_data.empty:\n",
    "            # è·å–ç¼“å­˜æ•°æ®çš„æœ€åæ—¥æœŸ\n",
    "            last_cached_date = cached_data.index.max().strftime(\"%Y%m%d\")\n",
    "\n",
    "            # å¦‚æœç¼“å­˜æ•°æ®å·²ç»åŒ…å«æ‰€éœ€çš„æ‰€æœ‰æ—¥æœŸï¼Œç›´æ¥è¿”å›\n",
    "            if last_cached_date >= end_date:\n",
    "                return cached_data, f\"ä»ç¼“å­˜è·å–è‚¡ç¥¨ {stock_code} æ•°æ®ï¼Œå…± {len(cached_data)} è¡Œ\"\n",
    "\n",
    "            # å¦åˆ™ï¼Œåªä¸‹è½½æ–°çš„æ•°æ®\n",
    "            start_date = (pd.to_datetime(last_cached_date) + timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "            st.info(f\"ç¼“å­˜æ•°æ®éœ€è¦æ›´æ–°ï¼Œä» {start_date} å¼€å§‹ä¸‹è½½æ–°æ•°æ®\")\n",
    "\n",
    "        try:\n",
    "            # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹\n",
    "            time.sleep(random.uniform(1, 3))\n",
    "\n",
    "            # ä½¿ç”¨å¸¦æœ‰é‡è¯•æœºåˆ¶çš„akshare\n",
    "            df = ak.stock_zh_a_hist(\n",
    "                symbol=stock_code,\n",
    "                period=\"daily\",\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                adjust=\"hfq\"  # ä½¿ç”¨åå¤æƒæ•°æ®ï¼Œä¾¿äºé•¿æœŸåˆ†æ\n",
    "            )\n",
    "\n",
    "            if df is not None and len(df) > 0:\n",
    "                # æ•°æ®é¢„å¤„ç†\n",
    "                df[\"æ—¥æœŸ\"] = pd.to_datetime(df[\"æ—¥æœŸ\"])\n",
    "                df = df.sort_values(\"æ—¥æœŸ\")\n",
    "                df.set_index(\"æ—¥æœŸ\", inplace=True)\n",
    "\n",
    "                # é€‰æ‹©ç‰¹å¾\n",
    "                available_features = [col for col in self.features if col in df.columns]\n",
    "                new_data = df[available_features].dropna()\n",
    "\n",
    "                # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡\n",
    "                new_data = self.add_technical_indicators(new_data)\n",
    "\n",
    "                # åˆå¹¶ç¼“å­˜æ•°æ®å’Œæ–°æ•°æ®\n",
    "                if cached_data is not None and not cached_data.empty:\n",
    "                    # ç¡®ä¿æ²¡æœ‰é‡å¤æ•°æ®\n",
    "                    combined_data = pd.concat([cached_data, new_data]).drop_duplicates()\n",
    "                    combined_data = combined_data[~combined_data.index.duplicated(keep='last')]\n",
    "                    combined_data = combined_data.sort_index()\n",
    "                else:\n",
    "                    combined_data = new_data\n",
    "\n",
    "                # ä¿å­˜åˆ°ç¼“å­˜\n",
    "                try:\n",
    "                    with open(cache_file, 'wb') as f:\n",
    "                        pickle.dump(combined_data, f)\n",
    "                    st.success(f\"è‚¡ç¥¨ {stock_code} æ•°æ®å·²ç¼“å­˜\")\n",
    "                except Exception as e:\n",
    "                    st.warning(f\"ä¿å­˜ç¼“å­˜æ•°æ®å¤±è´¥: {e}\")\n",
    "\n",
    "                return combined_data, f\"æˆåŠŸè·å–è‚¡ç¥¨ {stock_code} æ•°æ®ï¼Œå…± {len(combined_data)} è¡Œ\"\n",
    "            else:\n",
    "                # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œè¿”å›ç¼“å­˜æ•°æ®\n",
    "                if cached_data is not None and not cached_data.empty:\n",
    "                    return cached_data, f\"æ— æ–°æ•°æ®ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œå…± {len(cached_data)} è¡Œ\"\n",
    "                else:\n",
    "                    return None, f\"è‚¡ç¥¨ {stock_code} è¿”å›ç©ºæ•°æ®\"\n",
    "\n",
    "        except Exception as e:\n",
    "            # å¦‚æœè·å–çœŸå®æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®æˆ–æ¨¡æ‹Ÿæ•°æ®\n",
    "            if cached_data is not None and not cached_data.empty:\n",
    "                st.warning(f\"è·å–è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®\")\n",
    "                return cached_data, f\"ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œå…± {len(cached_data)} è¡Œ\"\n",
    "            else:\n",
    "                st.warning(f\"è·å–è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®\")\n",
    "                return self.create_simulated_data(stock_code)\n",
    "\n",
    "    def add_technical_indicators(self, data):\n",
    "        \"\"\"æ·»åŠ æŠ€æœ¯æŒ‡æ ‡\"\"\"\n",
    "        try:\n",
    "            # ç§»åŠ¨å¹³å‡çº¿\n",
    "            data['MA5'] = data['æ”¶ç›˜'].rolling(window=5).mean()\n",
    "            data['MA10'] = data['æ”¶ç›˜'].rolling(window=10).mean()\n",
    "            data['MA20'] = data['æ”¶ç›˜'].rolling(window=20).mean()\n",
    "\n",
    "            # æ‰‹åŠ¨è®¡ç®—RSI\n",
    "            def calculate_rsi(prices, window=14):\n",
    "                delta = prices.diff()\n",
    "                gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "                loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "                rs = gain / loss\n",
    "                rsi = 100 - (100 / (1 + rs))\n",
    "                return rsi\n",
    "\n",
    "            data['RSI'] = calculate_rsi(data['æ”¶ç›˜'])\n",
    "\n",
    "            # æ‰‹åŠ¨è®¡ç®—MACD\n",
    "            def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "                ema_fast = prices.ewm(span=fast).mean()\n",
    "                ema_slow = prices.ewm(span=slow).mean()\n",
    "                macd = ema_fast - ema_slow\n",
    "                macd_signal = macd.ewm(span=signal).mean()\n",
    "                macd_histogram = macd - macd_signal\n",
    "                return macd, macd_signal, macd_histogram\n",
    "\n",
    "            macd, macd_signal, macd_histogram = calculate_macd(data['æ”¶ç›˜'])\n",
    "            data['MACD'] = macd\n",
    "            data['MACD_Signal'] = macd_signal\n",
    "            data['MACD_Histogram'] = macd_histogram\n",
    "\n",
    "            # å¸ƒæ—å¸¦\n",
    "            def calculate_bollinger_bands(prices, window=20, num_std=2):\n",
    "                rolling_mean = prices.rolling(window=window).mean()\n",
    "                rolling_std = prices.rolling(window=window).std()\n",
    "                upper_band = rolling_mean + (rolling_std * num_std)\n",
    "                lower_band = rolling_mean - (rolling_std * num_std)\n",
    "                return upper_band, rolling_mean, lower_band\n",
    "\n",
    "            bb_upper, bb_middle, bb_lower = calculate_bollinger_bands(data['æ”¶ç›˜'])\n",
    "            data['BB_Upper'] = bb_upper\n",
    "            data['BB_Middle'] = bb_middle\n",
    "            data['BB_Lower'] = bb_lower\n",
    "\n",
    "            # åˆ é™¤NaNå€¼\n",
    "            data = data.dropna()\n",
    "\n",
    "        except Exception as e:\n",
    "            st.warning(f\"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    def create_simulated_data(self, stock_name=\"æ¨¡æ‹Ÿè‚¡ç¥¨\", start_date=\"2020-01-01\", end_date=None):\n",
    "        \"\"\"åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•\"\"\"\n",
    "        if end_date is None:\n",
    "            end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "        np.random.seed(42)\n",
    "\n",
    "        n = len(dates)\n",
    "        trend = np.linspace(100, 200, n)\n",
    "        noise = np.cumsum(np.random.randn(n) * 0.8)\n",
    "        price = trend + noise\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'å¼€ç›˜': price + np.random.randn(n) * 2,\n",
    "            'æœ€é«˜': price + np.abs(np.random.randn(n)) * 3 + 2,\n",
    "            'æœ€ä½': price - np.abs(np.random.randn(n)) * 3 - 2,\n",
    "            'æ”¶ç›˜': price,\n",
    "            'æˆäº¤é‡': np.random.randint(1000000, 20000000, n) + np.cumsum(np.random.randn(n) * 1000000).astype(int)\n",
    "        }, index=dates)\n",
    "\n",
    "        # ä¸ºæ¨¡æ‹Ÿæ•°æ®æ·»åŠ æŠ€æœ¯æŒ‡æ ‡\n",
    "        df = self.add_technical_indicators(df)\n",
    "\n",
    "        return df, f\"åˆ›å»º {stock_name} æ¨¡æ‹Ÿæ•°æ®ï¼Œå…± {len(df)} è¡Œ\"\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        \"\"\"å‡†å¤‡è®­ç»ƒæ•°æ®\"\"\"\n",
    "        # ä½¿ç”¨æ›´å¤šç‰¹å¾è¿›è¡Œè®­ç»ƒ\n",
    "        training_features = [\"å¼€ç›˜\", \"æœ€é«˜\", \"æœ€ä½\", \"æ”¶ç›˜\", \"æˆäº¤é‡\", \"MA5\", \"MA10\", \"MA20\", \"RSI\", \"MACD\"]\n",
    "        available_features = [col for col in training_features if col in data.columns]\n",
    "\n",
    "        if len(available_features) < 5:  # å¦‚æœæ²¡æœ‰æŠ€æœ¯æŒ‡æ ‡ï¼Œä½¿ç”¨åŸºæœ¬ç‰¹å¾\n",
    "            available_features = self.features\n",
    "\n",
    "        scaled_data = self.scaler.fit_transform(data[available_features])\n",
    "\n",
    "        def create_sequences(data, time_window, target_idx):\n",
    "            X, y = [], []\n",
    "            for i in range(time_window, len(data)):\n",
    "                X.append(data[i - time_window:i])\n",
    "                y.append(data[i, target_idx])\n",
    "            return np.array(X), np.array(y)\n",
    "\n",
    "        train_size = int(len(scaled_data) * 0.8)\n",
    "        train_data = scaled_data[:train_size]\n",
    "        test_data = scaled_data[train_size:]\n",
    "\n",
    "        # æ‰¾åˆ°æ”¶ç›˜ä»·åœ¨ç‰¹å¾ä¸­çš„ç´¢å¼•\n",
    "        close_idx = available_features.index(\"æ”¶ç›˜\") if \"æ”¶ç›˜\" in available_features else 3\n",
    "\n",
    "        train_X, train_y = create_sequences(train_data, self.time_window, close_idx)\n",
    "        test_X, test_y = create_sequences(test_data, self.time_window, close_idx)\n",
    "\n",
    "        return train_X, train_y, test_X, test_y, train_size, available_features\n",
    "\n",
    "    def build_model(self, input_shape, model_type=\"LSTM+Attention\", lstm_units=64, gru_units=64,\n",
    "                    attention_heads=4, dense_units=32, dropout_rate=0.2):\n",
    "        \"\"\"æ„å»ºæ¨¡å‹\"\"\"\n",
    "        inputs = Input(shape=input_shape)\n",
    "\n",
    "        if model_type == \"LSTM+Attention\":\n",
    "            lstm_out = LSTM(lstm_units, return_sequences=True, activation='tanh')(inputs)\n",
    "            lstm_out = Dropout(dropout_rate)(lstm_out)\n",
    "            attention_out = MultiHeadAttention(num_heads=attention_heads, key_dim=32)(lstm_out, lstm_out)\n",
    "            combined = lstm_out + attention_out\n",
    "            last_step = tf.keras.layers.Lambda(lambda x: x[:, -1, :])(combined)\n",
    "\n",
    "        elif model_type == \"GRU\":\n",
    "            gru_out = GRU(gru_units, return_sequences=True, activation='tanh')(inputs)\n",
    "            gru_out = Dropout(dropout_rate)(gru_out)\n",
    "            last_step = tf.keras.layers.Lambda(lambda x: x[:, -1, :])(gru_out)\n",
    "\n",
    "        elif model_type == \"CNN+LSTM\":\n",
    "            # CNNéƒ¨åˆ†\n",
    "            conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "            pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "            conv2 = Conv1D(filters=32, kernel_size=3, activation='relu')(pool1)\n",
    "            pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "            # LSTMéƒ¨åˆ†\n",
    "            lstm_out = LSTM(lstm_units, return_sequences=False)(pool2)\n",
    "            last_step = Dropout(dropout_rate)(lstm_out)\n",
    "\n",
    "        elif model_type == \"Simple LSTM\":\n",
    "            lstm_out = LSTM(lstm_units, return_sequences=False)(inputs)\n",
    "            last_step = Dropout(dropout_rate)(lstm_out)\n",
    "\n",
    "        else:  # é»˜è®¤LSTM+Attention\n",
    "            lstm_out = LSTM(lstm_units, return_sequences=True, activation='tanh')(inputs)\n",
    "            lstm_out = Dropout(dropout_rate)(lstm_out)\n",
    "            attention_out = MultiHeadAttention(num_heads=attention_heads, key_dim=32)(lstm_out, lstm_out)\n",
    "            combined = lstm_out + attention_out\n",
    "            last_step = tf.keras.layers.Lambda(lambda x: x[:, -1, :])(combined)\n",
    "\n",
    "        output = Dense(dense_units, activation='relu')(last_step)\n",
    "        output = Dropout(dropout_rate)(output)\n",
    "        output = Dense(1, activation='linear')(output)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=output)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "\n",
    "        self.model_type = model_type\n",
    "        return model\n",
    "\n",
    "    def train_model(self, stock_codes, epochs=50, use_simulated=False, model_type=\"LSTM+Attention\",\n",
    "                    lstm_units=64, gru_units=64, attention_heads=4, dense_units=32, dropout_rate=0.2,\n",
    "                    progress_bar=None, status_text=None):\n",
    "        \"\"\"è®­ç»ƒæ¨¡å‹\"\"\"\n",
    "        all_train_X, all_train_y = [], []\n",
    "        all_test_X, all_test_y = [], []\n",
    "        stock_data_info = []\n",
    "\n",
    "        if not isinstance(stock_codes, list):\n",
    "            stock_codes = [stock_codes]\n",
    "\n",
    "        for stock_code in stock_codes:\n",
    "            if use_simulated:\n",
    "                data, info = self.create_simulated_data(stock_code)\n",
    "            else:\n",
    "                data, info = self.get_stock_data(stock_code)\n",
    "                if data is None:\n",
    "                    data, info = self.create_simulated_data(stock_code)\n",
    "\n",
    "            stock_data_info.append(f\"{stock_code}: {info}\")\n",
    "\n",
    "            train_X, train_y, test_X, test_y, _, features_used = self.prepare_data(data)\n",
    "            self.features = features_used  # æ›´æ–°ä½¿ç”¨çš„ç‰¹å¾åˆ—è¡¨\n",
    "            self.close_idx = features_used.index(\"æ”¶ç›˜\") if \"æ”¶ç›˜\" in features_used else 3\n",
    "\n",
    "            all_train_X.append(train_X)\n",
    "            all_train_y.append(train_y)\n",
    "            all_test_X.append(test_X)\n",
    "            all_test_y.append(test_y)\n",
    "\n",
    "        # åˆå¹¶æ•°æ®\n",
    "        train_X = np.vstack(all_train_X)\n",
    "        train_y = np.hstack(all_train_y)\n",
    "        test_X = np.vstack(all_test_X)\n",
    "        test_y = np.hstack(all_test_y)\n",
    "\n",
    "        # æ„å»ºæ¨¡å‹\n",
    "        self.model = self.build_model(\n",
    "            (self.time_window, len(self.features)),\n",
    "            model_type=model_type,\n",
    "            lstm_units=lstm_units,\n",
    "            gru_units=gru_units,\n",
    "            attention_heads=attention_heads,\n",
    "            dense_units=dense_units,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "\n",
    "        # è®­ç»ƒæ¨¡å‹\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "        callbacks = [early_stopping]\n",
    "        if progress_bar and status_text:\n",
    "            callbacks.append(TrainingProgressCallback(progress_bar, status_text, epochs))\n",
    "\n",
    "        history = self.model.fit(\n",
    "            train_X, train_y,\n",
    "            epochs=epochs,\n",
    "            batch_size=32,\n",
    "            validation_data=(test_X, test_y),\n",
    "            verbose=0,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "\n",
    "        self.is_trained = True\n",
    "\n",
    "        return history, train_X, train_y, test_X, test_y, stock_data_info\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"å¯¹ç»™å®šæ•°æ®è¿›è¡Œé¢„æµ‹\"\"\"\n",
    "        if not self.is_trained:\n",
    "            return None, \"æ¨¡å‹æœªè®­ç»ƒ\"\n",
    "\n",
    "        # ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„ç‰¹å¾\n",
    "        available_features = [col for col in self.features if col in data.columns]\n",
    "        if len(available_features) < len(self.features):\n",
    "            st.warning(f\"æ•°æ®ç¼ºå°‘æŸäº›ç‰¹å¾ï¼Œä½¿ç”¨å¯ç”¨ç‰¹å¾: {available_features}\")\n",
    "\n",
    "        data_to_use = data[available_features]\n",
    "        scaled_data = self.scaler.transform(data_to_use)\n",
    "\n",
    "        X, y = [], []\n",
    "        close_idx = available_features.index(\"æ”¶ç›˜\") if \"æ”¶ç›˜\" in available_features else 3\n",
    "\n",
    "        for i in range(self.time_window, len(scaled_data)):\n",
    "            X.append(scaled_data[i - self.time_window:i])\n",
    "            y.append(scaled_data[i, close_idx])\n",
    "\n",
    "        X, y = np.array(X), np.array(y)\n",
    "\n",
    "        predictions = self.model.predict(X, verbose=0)\n",
    "\n",
    "        # åå½’ä¸€åŒ–\n",
    "        predictions_inv = self.inverse_transform_pred(predictions, available_features, close_idx)\n",
    "        y_inv = self.inverse_transform_pred(y.reshape(-1, 1), available_features, close_idx)\n",
    "\n",
    "        return predictions_inv, y_inv\n",
    "\n",
    "    def predict_future(self, data, days=30):\n",
    "        \"\"\"é¢„æµ‹æœªæ¥ä»·æ ¼èµ°åŠ¿\"\"\"\n",
    "        if not self.is_trained:\n",
    "            return None, \"æ¨¡å‹æœªè®­ç»ƒ\"\n",
    "\n",
    "        # ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„ç‰¹å¾\n",
    "        available_features = [col for col in self.features if col in data.columns]\n",
    "        close_idx = available_features.index(\"æ”¶ç›˜\") if \"æ”¶ç›˜\" in available_features else 3\n",
    "\n",
    "        last_sequence = data[available_features].tail(self.time_window)\n",
    "        last_sequence_scaled = self.scaler.transform(last_sequence)\n",
    "\n",
    "        future_predictions = []\n",
    "        current_sequence = last_sequence_scaled.copy()\n",
    "\n",
    "        for _ in range(days):\n",
    "            next_pred = self.model.predict(current_sequence.reshape(1, self.time_window, len(available_features)),\n",
    "                                           verbose=0)\n",
    "            future_predictions.append(next_pred[0, 0])\n",
    "\n",
    "            new_day = current_sequence[-1].copy()\n",
    "            new_day[close_idx] = next_pred[0, 0]\n",
    "            current_sequence = np.vstack([current_sequence[1:], new_day])\n",
    "\n",
    "        future_predictions = self.inverse_transform_pred(np.array(future_predictions).reshape(-1, 1),\n",
    "                                                         available_features, close_idx)\n",
    "\n",
    "        return future_predictions\n",
    "\n",
    "    def inverse_transform_pred(self, y_pred, features, close_idx):\n",
    "        \"\"\"åå½’ä¸€åŒ–é¢„æµ‹ç»“æœ\"\"\"\n",
    "        y_reshaped = np.zeros(shape=(len(y_pred), len(features)))\n",
    "        y_reshaped[:, close_idx] = y_pred.flatten()\n",
    "        return self.scaler.inverse_transform(y_reshaped)[:, close_idx]\n",
    "\n",
    "    def evaluate_model(self, true_values, predictions):\n",
    "        \"\"\"è¯„ä¼°æ¨¡å‹æ€§èƒ½\"\"\"\n",
    "        mae = mean_absolute_error(true_values, predictions)\n",
    "        mse = mean_squared_error(true_values, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(true_values, predictions)\n",
    "\n",
    "        # è®¡ç®—æ–¹å‘å‡†ç¡®ç‡\n",
    "        if len(true_values) > 1:\n",
    "            true_direction = np.diff(true_values) > 0\n",
    "            pred_direction = np.diff(predictions) > 0\n",
    "            direction_accuracy = np.mean(true_direction == pred_direction) * 100\n",
    "        else:\n",
    "            direction_accuracy = 0\n",
    "\n",
    "        return {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'Direction_Accuracy': direction_accuracy\n",
    "        }\n",
    "\n",
    "    def backtest_strategy(self, data, predictions, strategy_type=\"simple\",\n",
    "                          initial_capital=100000, transaction_cost=0.001,\n",
    "                          rsi_oversold=30, rsi_overbought=70,\n",
    "                          ma_short=5, ma_long=20, stop_loss=0.05, take_profit=0.1):\n",
    "        \"\"\"\n",
    "        å›æµ‹é‡åŒ–ç­–ç•¥\n",
    "        æ”¯æŒå¤šç§ç­–ç•¥ç±»å‹\n",
    "        \"\"\"\n",
    "        if len(data) != len(predictions) + self.time_window:\n",
    "            return None, \"æ•°æ®é•¿åº¦ä¸åŒ¹é…\"\n",
    "\n",
    "        # è·å–å®é™…ä»·æ ¼ï¼ˆä¸é¢„æµ‹å¯¹åº”çš„éƒ¨åˆ†ï¼‰\n",
    "        actual_prices = data['æ”¶ç›˜'].values[self.time_window:]\n",
    "        actual_dates = data.index[self.time_window:]\n",
    "\n",
    "        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡\n",
    "        data_with_indicators = self.add_technical_indicators(data)\n",
    "\n",
    "        # åˆå§‹åŒ–å˜é‡\n",
    "        capital = initial_capital\n",
    "        position = 0  # 0è¡¨ç¤ºç©ºä»“ï¼Œ1è¡¨ç¤ºæ»¡ä»“\n",
    "        shares = 0\n",
    "        entry_price = 0\n",
    "        trades = []\n",
    "        portfolio_values = []\n",
    "\n",
    "        # åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡å˜é‡\n",
    "        rsi = 50\n",
    "        ma_short_val = actual_prices[0] if len(actual_prices) > 0 else 0\n",
    "        ma_long_val = actual_prices[0] if len(actual_prices) > 0 else 0\n",
    "\n",
    "        for i in range(1, len(predictions)):\n",
    "            if i >= len(actual_prices):\n",
    "                break\n",
    "\n",
    "            current_price = actual_prices[i]\n",
    "            current_date = actual_dates[i]\n",
    "\n",
    "            # è·å–æŠ€æœ¯æŒ‡æ ‡ - æ·»åŠ è¾¹ç•Œæ£€æŸ¥\n",
    "            try:\n",
    "                if 'RSI' in data_with_indicators.columns and self.time_window + i < len(data_with_indicators):\n",
    "                    rsi = data_with_indicators['RSI'].iloc[self.time_window + i]\n",
    "                else:\n",
    "                    rsi = 50\n",
    "\n",
    "                if f'MA{ma_short}' in data_with_indicators.columns and self.time_window + i < len(data_with_indicators):\n",
    "                    ma_short_val = data_with_indicators[f'MA{ma_short}'].iloc[self.time_window + i]\n",
    "                else:\n",
    "                    ma_short_val = current_price\n",
    "\n",
    "                if f'MA{ma_long}' in data_with_indicators.columns and self.time_window + i < len(data_with_indicators):\n",
    "                    ma_long_val = data_with_indicators[f'MA{ma_long}'].iloc[self.time_window + i]\n",
    "                else:\n",
    "                    ma_long_val = current_price\n",
    "            except (IndexError, KeyError):\n",
    "                # å¦‚æœç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤å€¼\n",
    "                rsi = 50\n",
    "                ma_short_val = current_price\n",
    "                ma_long_val = current_price\n",
    "\n",
    "            # é¢„æµ‹æ˜æ—¥æ¶¨è·Œ\n",
    "            predicted_tomorrow = predictions[i]\n",
    "            predicted_today = predictions[i - 1]\n",
    "            predicted_change = (predicted_tomorrow - predicted_today) / predicted_today if predicted_today != 0 else 0\n",
    "\n",
    "            # ç­–ç•¥å†³ç­–\n",
    "            trade_signal = 0  # 0: æ— ä¿¡å·, 1: ä¹°å…¥, -1: å–å‡º\n",
    "\n",
    "            if strategy_type == \"simple\":\n",
    "                # ç®€å•ç­–ç•¥ï¼šåŸºäºé¢„æµ‹æ–¹å‘\n",
    "                if predicted_tomorrow > predicted_today and position == 0:\n",
    "                    trade_signal = 1\n",
    "                elif predicted_tomorrow < predicted_today and position == 1:\n",
    "                    trade_signal = -1\n",
    "\n",
    "            elif strategy_type == \"rsi_based\":\n",
    "                # RSIç­–ç•¥ï¼šç»“åˆRSIè¶…ä¹°è¶…å–\n",
    "                if rsi < rsi_oversold and predicted_change > 0 and position == 0:\n",
    "                    trade_signal = 1\n",
    "                elif rsi > rsi_overbought and predicted_change < 0 and position == 1:\n",
    "                    trade_signal = -1\n",
    "\n",
    "            elif strategy_type == \"ma_crossover\":\n",
    "                # ç§»åŠ¨å¹³å‡çº¿äº¤å‰ç­–ç•¥\n",
    "                ma_signal = 1 if ma_short_val > ma_long_val else -1\n",
    "                if ma_signal > 0 and predicted_change > 0 and position == 0:\n",
    "                    trade_signal = 1\n",
    "                elif ma_signal < 0 and predicted_change < 0 and position == 1:\n",
    "                    trade_signal = -1\n",
    "\n",
    "            elif strategy_type == \"combined\":\n",
    "                # ç»¼åˆç­–ç•¥ï¼šç»“åˆå¤šç§æŒ‡æ ‡\n",
    "                ma_signal = 1 if ma_short_val > ma_long_val else -1\n",
    "                rsi_signal = 1 if rsi < rsi_oversold else (-1 if rsi > rsi_overbought else 0)\n",
    "\n",
    "                buy_condition = (predicted_change > 0.01 and\n",
    "                                 (ma_signal > 0 or rsi_signal > 0) and\n",
    "                                 position == 0)\n",
    "\n",
    "                sell_condition = (predicted_change < -0.01 and\n",
    "                                  (ma_signal < 0 or rsi_signal < 0) and\n",
    "                                  position == 1)\n",
    "\n",
    "                if buy_condition:\n",
    "                    trade_signal = 1\n",
    "                elif sell_condition:\n",
    "                    trade_signal = -1\n",
    "\n",
    "            elif strategy_type == \"momentum\":\n",
    "                # åŠ¨é‡ç­–ç•¥ï¼šåŸºäºä»·æ ¼åŠ¨é‡\n",
    "                if i >= 5:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®\n",
    "                    price_momentum = (current_price - actual_prices[i - 5]) / actual_prices[i - 5] if actual_prices[\n",
    "                                                                                                          i - 5] != 0 else 0\n",
    "                else:\n",
    "                    price_momentum = 0\n",
    "\n",
    "                if price_momentum > 0.02 and predicted_change > 0.01 and position == 0:\n",
    "                    trade_signal = 1\n",
    "                elif price_momentum < -0.02 and predicted_change < -0.01 and position == 1:\n",
    "                    trade_signal = -1\n",
    "\n",
    "            # æ­¢æŸæ­¢ç›ˆæ£€æŸ¥\n",
    "            if position == 1:\n",
    "                profit_pct = (current_price - entry_price) / entry_price if entry_price != 0 else 0\n",
    "                if profit_pct <= -stop_loss or profit_pct >= take_profit:\n",
    "                    trade_signal = -1  # å¼ºåˆ¶å–å‡º\n",
    "\n",
    "            # æ‰§è¡Œäº¤æ˜“\n",
    "            if trade_signal == 1 and position == 0:  # ä¹°å…¥\n",
    "                shares = capital / current_price\n",
    "                capital = 0\n",
    "                position = 1\n",
    "                entry_price = current_price\n",
    "                trades.append(('BUY', current_date, current_price, f\"é¢„æµ‹æ¶¨å¹…: {predicted_change:.2%}\"))\n",
    "\n",
    "            elif trade_signal == -1 and position == 1:  # å–å‡º\n",
    "                capital = shares * current_price * (1 - transaction_cost)\n",
    "                shares = 0\n",
    "                position = 0\n",
    "                profit = (current_price - entry_price) / entry_price if entry_price != 0 else 0\n",
    "                trades.append(('SELL', current_date, current_price, f\"ç›ˆäº: {profit:.2%}\"))\n",
    "\n",
    "            # è®¡ç®—å½“å‰æŠ•èµ„ç»„åˆä»·å€¼\n",
    "            if position == 1:\n",
    "                portfolio_value = shares * current_price\n",
    "            else:\n",
    "                portfolio_value = capital\n",
    "\n",
    "            portfolio_values.append(portfolio_value)\n",
    "\n",
    "        # è®¡ç®—æœ€ç»ˆæ”¶ç›Š\n",
    "        if position == 1:  # å¦‚æœæœ€åè¿˜æŒæœ‰è‚¡ç¥¨ï¼ŒæŒ‰æœ€åä»·æ ¼å–å‡º\n",
    "            final_value = shares * actual_prices[-1] * (1 - transaction_cost)\n",
    "            profit = (actual_prices[-1] - entry_price) / entry_price if entry_price != 0 else 0\n",
    "            trades.append(('SELL', actual_dates[-1], actual_prices[-1], f\"æœ€ç»ˆç›ˆäº: {profit:.2%}\"))\n",
    "        else:\n",
    "            final_value = capital\n",
    "\n",
    "        total_return = (final_value - initial_capital) / initial_capital * 100\n",
    "        buy_hold_return = (actual_prices[-1] - actual_prices[0]) / actual_prices[0] * 100 if actual_prices[\n",
    "                                                                                                 0] != 0 else 0\n",
    "\n",
    "        # è®¡ç®—æœ€å¤§å›æ’¤\n",
    "        if len(portfolio_values) > 0:\n",
    "            portfolio_array = np.array(portfolio_values)\n",
    "            peak = np.maximum.accumulate(portfolio_array)\n",
    "            drawdown = (portfolio_array - peak) / peak * 100\n",
    "            max_drawdown = np.min(drawdown) if len(drawdown) > 0 else 0\n",
    "        else:\n",
    "            max_drawdown = 0\n",
    "\n",
    "        # è®¡ç®—å¤æ™®æ¯”ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰\n",
    "        if len(portfolio_values) > 1:\n",
    "            portfolio_array = np.array(portfolio_values)\n",
    "            returns = np.diff(portfolio_array) / portfolio_array[:-1]\n",
    "            if len(returns) > 0 and np.std(returns) > 0:\n",
    "                sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(252)\n",
    "            else:\n",
    "                sharpe_ratio = 0\n",
    "        else:\n",
    "            sharpe_ratio = 0\n",
    "\n",
    "        # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡\n",
    "        total_days = len(portfolio_values)\n",
    "        if total_days > 0 and initial_capital > 0:\n",
    "            annual_return = (final_value / initial_capital) ** (365 / total_days) - 1\n",
    "        else:\n",
    "            annual_return = 0\n",
    "\n",
    "        # è®¡ç®—èƒœç‡\n",
    "        winning_trades = 0\n",
    "        total_trades = len([t for t in trades if t[0] == 'SELL'])\n",
    "\n",
    "        for i in range(1, len(trades)):\n",
    "            if trades[i][0] == 'SELL':\n",
    "                # æŸ¥æ‰¾å¯¹åº”çš„ä¹°å…¥äº¤æ˜“\n",
    "                for j in range(i - 1, -1, -1):\n",
    "                    if trades[j][0] == 'BUY':\n",
    "                        buy_price = trades[j][2]\n",
    "                        sell_price = trades[i][2]\n",
    "                        if sell_price > buy_price:\n",
    "                            winning_trades += 1\n",
    "                        break\n",
    "\n",
    "        win_rate = winning_trades / total_trades * 100 if total_trades > 0 else 0\n",
    "\n",
    "        return {\n",
    "            'initial_capital': initial_capital,\n",
    "            'final_value': final_value,\n",
    "            'total_return': total_return,\n",
    "            'annual_return': annual_return * 100,\n",
    "            'buy_hold_return': buy_hold_return,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'win_rate': win_rate,\n",
    "            'total_trades': total_trades,\n",
    "            'trades': trades,\n",
    "            'portfolio_values': portfolio_values,\n",
    "            'dates': actual_dates[1:min(len(predictions), len(actual_dates))],\n",
    "            'strategy_type': strategy_type\n",
    "        }, \"å›æµ‹å®Œæˆ\"\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"ä¿å­˜æ¨¡å‹å’Œé…ç½®\"\"\"\n",
    "        if self.model is None:\n",
    "            return False, \"æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹å¯ä¿å­˜\"\n",
    "\n",
    "        # åˆ›å»ºç›®å½•\n",
    "        os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)\n",
    "\n",
    "        # ä¿å­˜æ¨¡å‹ - ä½¿ç”¨SavedModelæ ¼å¼é¿å…è‡ªå®šä¹‰å±‚é—®é¢˜\n",
    "        model_path = filepath if filepath.endswith('.h5') else filepath + '.h5'\n",
    "\n",
    "        # ä½¿ç”¨tf.saved_model.saveä¿å­˜æ•´ä¸ªæ¨¡å‹\n",
    "        saved_model_dir = model_path.replace('.h5', '')\n",
    "        tf.saved_model.save(self.model, saved_model_dir)\n",
    "\n",
    "        # ä¿å­˜scalerå’Œå…¶ä»–é…ç½®\n",
    "        config = {\n",
    "            'time_window': self.time_window,\n",
    "            'features': self.features,\n",
    "            'close_idx': self.close_idx,\n",
    "            'is_trained': self.is_trained,\n",
    "            'model_type': self.model_type,\n",
    "            'scaler_params': {\n",
    "                'min_': self.scaler.min_,\n",
    "                'scale_': self.scaler.scale_,\n",
    "                'data_min_': self.scaler.data_min_,\n",
    "                'data_max_': self.scaler.data_max_,\n",
    "                'data_range_': self.scaler.data_range_\n",
    "            }\n",
    "        }\n",
    "\n",
    "        config_path = filepath.replace('.h5', '_config.pkl') if filepath.endswith('.h5') else filepath + '_config.pkl'\n",
    "        with open(config_path, 'wb') as f:\n",
    "            pickle.dump(config, f)\n",
    "\n",
    "        return True, f\"æ¨¡å‹å·²ä¿å­˜åˆ° {saved_model_dir}\"\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"åŠ è½½æ¨¡å‹å’Œé…ç½®\"\"\"\n",
    "        # å¤„ç†æ–‡ä»¶è·¯å¾„\n",
    "        if filepath.endswith('.h5'):\n",
    "            saved_model_dir = filepath.replace('.h5', '')\n",
    "            config_path = filepath.replace('.h5', '_config.pkl')\n",
    "        else:\n",
    "            saved_model_dir = filepath\n",
    "            config_path = filepath + '_config.pkl'\n",
    "\n",
    "        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "        if not os.path.exists(saved_model_dir):\n",
    "            return False, f\"æ¨¡å‹æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {saved_model_dir}\"\n",
    "\n",
    "        if not os.path.exists(config_path):\n",
    "            return False, f\"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}\"\n",
    "\n",
    "        try:\n",
    "            # åŠ è½½æ¨¡å‹ - ä½¿ç”¨tf.saved_model.load\n",
    "            self.model = tf.saved_model.load(saved_model_dir)\n",
    "\n",
    "            # è·å–callableçš„signatureç”¨äºé¢„æµ‹\n",
    "            if hasattr(self.model, 'signatures') and 'serving_default' in self.model.signatures:\n",
    "                self.model = self.model.signatures['serving_default']\n",
    "            else:\n",
    "                # å¦‚æœæ— æ³•è·å–serving_defaultï¼Œå°è¯•ç›´æ¥è°ƒç”¨\n",
    "                self.model = self.model\n",
    "\n",
    "            # åŠ è½½é…ç½®\n",
    "            with open(config_path, 'rb') as f:\n",
    "                config = pickle.load(f)\n",
    "\n",
    "            self.time_window = config['time_window']\n",
    "            self.features = config['features']\n",
    "            self.close_idx = config['close_idx']\n",
    "            self.is_trained = config['is_trained']\n",
    "            self.model_type = config.get('model_type', 'LSTM+Attention')\n",
    "\n",
    "            # æ¢å¤scaler\n",
    "            self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            self.scaler.min_ = config['scaler_params']['min_']\n",
    "            self.scaler.scale_ = config['scaler_params']['scale_']\n",
    "            self.scaler.data_min_ = config['scaler_params']['data_min_']\n",
    "            self.scaler.data_max_ = config['scaler_params']['data_max_']\n",
    "            self.scaler.data_range_ = config['scaler_params']['data_range_']\n",
    "\n",
    "            return True, f\"æ¨¡å‹å·²ä» {saved_model_dir} åŠ è½½\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return False, f\"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}\"\n",
    "\n",
    "\n",
    "# åˆå§‹åŒ–é¢„æµ‹å™¨\n",
    "if 'predictor' not in st.session_state:\n",
    "    st.session_state.predictor = StockPredictor()\n",
    "    st.session_state.model_trained = False\n",
    "    st.session_state.training_history = None\n",
    "\n",
    "# ç•Œé¢è®¾è®¡\n",
    "st.title(\"ğŸ“ˆ æ™ºèƒ½è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ\")\n",
    "st.markdown(\"ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œå¤šè‚¡ç¥¨è®­ç»ƒã€é¢„æµ‹å’Œé‡åŒ–å›æµ‹\")\n",
    "\n",
    "# ä¾§è¾¹æ \n",
    "st.sidebar.header(\"æ¨¡å‹é…ç½®\")\n",
    "\n",
    "# æ—¶é—´çª—å£è®¾ç½®\n",
    "time_window = st.sidebar.slider(\"æ—¶é—´çª—å£å¤§å°\", min_value=10, max_value=60, value=30, step=5)\n",
    "st.session_state.predictor.time_window = time_window\n",
    "\n",
    "# ä¸»ç•Œé¢é€‰é¡¹å¡\n",
    "tab1, tab2, tab3, tab4, tab5 = st.tabs([\"ğŸš€ æ¨¡å‹è®­ç»ƒ\", \"ğŸ” è‚¡ç¥¨éªŒè¯\", \"ğŸ”® æœªæ¥é¢„æµ‹\", \"ğŸ“Š é‡åŒ–å›æµ‹\", \"ğŸ’¾ æ¨¡å‹ç®¡ç†\"])\n",
    "\n",
    "with tab1:\n",
    "    st.header(\"æ¨¡å‹è®­ç»ƒ\")\n",
    "\n",
    "    col1, col2 = st.columns([2, 1])\n",
    "\n",
    "    with col1:\n",
    "        st.subheader(\"è®­ç»ƒå‚æ•°\")\n",
    "\n",
    "        # è‚¡ç¥¨ä»£ç è¾“å…¥\n",
    "        train_stocks = st.text_area(\n",
    "            \"è®­ç»ƒè‚¡ç¥¨ä»£ç ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰\",\n",
    "            value=\"600519,000858,300750\",\n",
    "            help=\"ä¾‹å¦‚ï¼š600519,000858,300750\"\n",
    "        )\n",
    "\n",
    "        # æ¨¡å‹é€‰æ‹©\n",
    "        model_type = st.selectbox(\n",
    "            \"é€‰æ‹©æ¨¡å‹ç±»å‹\",\n",
    "            [\"LSTM+Attention\", \"GRU\", \"CNN+LSTM\", \"Simple LSTM\"],\n",
    "            help=\"é€‰æ‹©ä¸åŒçš„ç¥ç»ç½‘ç»œæ¶æ„\"\n",
    "        )\n",
    "\n",
    "        # æ¨¡å‹å‚æ•°\n",
    "        col1a, col1b = st.columns(2)\n",
    "        with col1a:\n",
    "            lstm_units = st.slider(\"LSTMå•å…ƒæ•°\", min_value=16, max_value=256, value=64, step=16)\n",
    "            gru_units = st.slider(\"GRUå•å…ƒæ•°\", min_value=16, max_value=256, value=64, step=16)\n",
    "            attention_heads = st.slider(\"æ³¨æ„åŠ›å¤´æ•°\", min_value=2, max_value=8, value=4, step=1)\n",
    "\n",
    "        with col1b:\n",
    "            dense_units = st.slider(\"å…¨è¿æ¥å±‚å•å…ƒæ•°\", min_value=16, max_value=128, value=32, step=8)\n",
    "            dropout_rate = st.slider(\"Dropoutæ¯”ç‡\", min_value=0.1, max_value=0.5, value=0.2, step=0.05)\n",
    "            epochs = st.number_input(\"è®­ç»ƒè½®æ•° (Epochs)\", min_value=10, max_value=500, value=50)\n",
    "\n",
    "        use_simulated = st.checkbox(\"ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆå½“çœŸå®æ•°æ®ä¸å¯ç”¨æ—¶ï¼‰\", value=True)\n",
    "\n",
    "    with col2:\n",
    "        st.subheader(\"è®­ç»ƒçŠ¶æ€\")\n",
    "        if st.session_state.model_trained:\n",
    "            st.success(\"âœ… æ¨¡å‹å·²è®­ç»ƒå®Œæˆ\")\n",
    "            if st.session_state.training_history:\n",
    "                st.write(f\"æ¨¡å‹ç±»å‹: {st.session_state.predictor.model_type}\")\n",
    "                st.write(f\"æœ€ç»ˆè®­ç»ƒæŸå¤±: {st.session_state.training_history.history['loss'][-1]:.4f}\")\n",
    "                st.write(f\"æœ€ç»ˆéªŒè¯æŸå¤±: {st.session_state.training_history.history['val_loss'][-1]:.4f}\")\n",
    "        else:\n",
    "            st.warning(\"â³ æ¨¡å‹æœªè®­ç»ƒ\")\n",
    "\n",
    "        # è®­ç»ƒè¿›åº¦åŒºåŸŸ\n",
    "        progress_bar = st.progress(0)\n",
    "        status_text = st.empty()\n",
    "\n",
    "    if st.button(\"å¼€å§‹è®­ç»ƒæ¨¡å‹\", type=\"primary\"):\n",
    "        if train_stocks.strip():\n",
    "            stock_list = [s.strip() for s in train_stocks.split(',') if s.strip()]\n",
    "\n",
    "            st.info(f\"å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨ {len(stock_list)} åªè‚¡ç¥¨æ•°æ®\")\n",
    "\n",
    "            with st.spinner(\"æ­£åœ¨è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç¨å€™...\"):\n",
    "                history, train_X, train_y, test_X, test_y, stock_info = st.session_state.predictor.train_model(\n",
    "                    stock_list,\n",
    "                    epochs=epochs,\n",
    "                    use_simulated=use_simulated,\n",
    "                    model_type=model_type,\n",
    "                    lstm_units=lstm_units,\n",
    "                    gru_units=gru_units,\n",
    "                    attention_heads=attention_heads,\n",
    "                    dense_units=dense_units,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    progress_bar=progress_bar,\n",
    "                    status_text=status_text\n",
    "                )\n",
    "\n",
    "                st.session_state.training_history = history\n",
    "                st.session_state.model_trained = True\n",
    "\n",
    "                # æ˜¾ç¤ºè®­ç»ƒç»“æœ\n",
    "                st.success(\"æ¨¡å‹è®­ç»ƒå®Œæˆï¼\")\n",
    "\n",
    "                # æ˜¾ç¤ºè‚¡ç¥¨æ•°æ®ä¿¡æ¯\n",
    "                st.subheader(\"è®­ç»ƒæ•°æ®ä¿¡æ¯\")\n",
    "                for info in stock_info:\n",
    "                    st.write(f\"- {info}\")\n",
    "\n",
    "                # ç»˜åˆ¶è®­ç»ƒå†å²\n",
    "                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "                ax1.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')\n",
    "                ax1.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')\n",
    "                ax1.set_title('æ¨¡å‹æŸå¤±')\n",
    "                ax1.set_xlabel('Epoch')\n",
    "                ax1.set_ylabel('Loss')\n",
    "                ax1.legend()\n",
    "                ax1.grid(True, alpha=0.3)\n",
    "\n",
    "                ax2.plot(history.history['mae'], label='è®­ç»ƒMAE')\n",
    "                ax2.plot(history.history['val_mae'], label='éªŒè¯MAE')\n",
    "                ax2.set_title('æ¨¡å‹MAE')\n",
    "                ax2.set_xlabel('Epoch')\n",
    "                ax2.set_ylabel('MAE')\n",
    "                ax2.legend()\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "\n",
    "                st.pyplot(fig)\n",
    "\n",
    "        else:\n",
    "            st.error(\"è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè‚¡ç¥¨ä»£ç \")\n",
    "\n",
    "with tab2:\n",
    "    st.header(\"è‚¡ç¥¨éªŒè¯\")\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        st.subheader(\"éªŒè¯å‚æ•°\")\n",
    "        validate_stock = st.text_input(\"éªŒè¯è‚¡ç¥¨ä»£ç \", value=\"000001\")\n",
    "        use_current_model = st.checkbox(\"ä½¿ç”¨å½“å‰è®­ç»ƒå¥½çš„æ¨¡å‹\", value=True)\n",
    "\n",
    "    with col2:\n",
    "        st.subheader(\"éªŒè¯è¯´æ˜\")\n",
    "        st.info(\"\"\"\n",
    "        ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æ–°çš„è‚¡ç¥¨æ•°æ®è¿›è¡ŒéªŒè¯ï¼Œ\n",
    "        è¯„ä¼°æ¨¡å‹åœ¨æœªè§è¿‡çš„è‚¡ç¥¨ä¸Šçš„è¡¨ç°ã€‚\n",
    "        \"\"\")\n",
    "\n",
    "    if st.button(\"å¼€å§‹éªŒè¯\", type=\"primary\"):\n",
    "        if validate_stock.strip() and st.session_state.model_trained:\n",
    "            with st.spinner(\"æ­£åœ¨éªŒè¯æ¨¡å‹...\"):\n",
    "                # è·å–éªŒè¯æ•°æ®\n",
    "                data, info = st.session_state.predictor.get_stock_data(validate_stock)\n",
    "                if data is None:\n",
    "                    st.error(f\"æ— æ³•è·å–è‚¡ç¥¨ {validate_stock} çš„æ•°æ®\")\n",
    "                else:\n",
    "                    st.success(info)\n",
    "\n",
    "                    # è¿›è¡Œé¢„æµ‹\n",
    "                    predictions, true_values = st.session_state.predictor.predict(data)\n",
    "\n",
    "                    if predictions is not None:\n",
    "                        # è¯„ä¼°æ¨¡å‹\n",
    "                        metrics = st.session_state.predictor.evaluate_model(true_values, predictions)\n",
    "\n",
    "                        # æ˜¾ç¤ºè¯„ä¼°ç»“æœ\n",
    "                        st.subheader(\"éªŒè¯ç»“æœ\")\n",
    "                        col1, col2, col3, col4 = st.columns(4)\n",
    "                        col1.metric(\"MAE\", f\"{metrics['MAE']:.4f}\")\n",
    "                        col2.metric(\"RMSE\", f\"{metrics['RMSE']:.4f}\")\n",
    "                        col3.metric(\"RÂ² Score\", f\"{metrics['R2']:.4f}\")\n",
    "                        col4.metric(\"æ–¹å‘å‡†ç¡®ç‡\", f\"{metrics['Direction_Accuracy']:.2f}%\")\n",
    "\n",
    "                        # ç»˜åˆ¶éªŒè¯ç»“æœ\n",
    "                        train_size = int(len(data) * 0.8)\n",
    "                        test_dates = data.index[train_size + time_window:]\n",
    "\n",
    "                        fig = go.Figure()\n",
    "                        fig.add_trace(go.Scatter(\n",
    "                            x=test_dates, y=true_values,\n",
    "                            mode='lines', name='çœŸå®ä»·æ ¼',\n",
    "                            line=dict(color='blue', width=2)\n",
    "                        ))\n",
    "                        fig.add_trace(go.Scatter(\n",
    "                            x=test_dates, y=predictions,\n",
    "                            mode='lines', name='é¢„æµ‹ä»·æ ¼',\n",
    "                            line=dict(color='red', width=1, dash='dash')\n",
    "                        ))\n",
    "                        fig.update_layout(\n",
    "                            title=f'{validate_stock} éªŒè¯ç»“æœ',\n",
    "                            xaxis_title='æ—¥æœŸ',\n",
    "                            yaxis_title='ä»·æ ¼ï¼ˆå…ƒï¼‰',\n",
    "                            hovermode='x unified'\n",
    "                        )\n",
    "                        st.plotly_chart(fig, use_container_width=True)\n",
    "        else:\n",
    "            st.error(\"è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–è¾“å…¥è‚¡ç¥¨ä»£ç \")\n",
    "\n",
    "with tab3:\n",
    "    st.header(\"æœªæ¥é¢„æµ‹\")\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        st.subheader(\"é¢„æµ‹å‚æ•°\")\n",
    "        predict_stock = st.text_input(\"é¢„æµ‹è‚¡ç¥¨ä»£ç \", value=\"600519\")\n",
    "        predict_days = st.slider(\"é¢„æµ‹å¤©æ•°\", min_value=5, max_value=60, value=30)\n",
    "        end_date = st.date_input(\"æ•°æ®æˆªæ­¢æ—¥æœŸ\", value=datetime.now())\n",
    "\n",
    "    with col2:\n",
    "        st.subheader(\"é¢„æµ‹è¯´æ˜\")\n",
    "        st.info(\"\"\"\n",
    "        åŸºäºå†å²æ•°æ®é¢„æµ‹æœªæ¥è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿ã€‚\n",
    "        é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚\n",
    "        \"\"\")\n",
    "\n",
    "    if st.button(\"å¼€å§‹é¢„æµ‹\", type=\"primary\"):\n",
    "        if predict_stock.strip() and st.session_state.model_trained:\n",
    "            with st.spinner(\"æ­£åœ¨è¿›è¡Œé¢„æµ‹...\"):\n",
    "                # è·å–æ•°æ®\n",
    "                end_date_str = end_date.strftime(\"%Y%m%d\")\n",
    "                data, info = st.session_state.predictor.get_stock_data(predict_stock, end_date=end_date_str)\n",
    "\n",
    "                if data is None:\n",
    "                    st.error(f\"æ— æ³•è·å–è‚¡ç¥¨ {predict_stock} çš„æ•°æ®\")\n",
    "                else:\n",
    "                    st.success(info)\n",
    "\n",
    "                    # è¿›è¡Œæœªæ¥é¢„æµ‹\n",
    "                    future_predictions = st.session_state.predictor.predict_future(data, days=predict_days)\n",
    "\n",
    "                    if future_predictions is not None:\n",
    "                        # åˆ›å»ºæœªæ¥æ—¥æœŸ\n",
    "                        last_date = data.index[-1]\n",
    "                        future_dates = [last_date + timedelta(days=i) for i in range(1, predict_days + 1)]\n",
    "\n",
    "                        # ç»˜åˆ¶é¢„æµ‹ç»“æœ\n",
    "                        fig = make_subplots(rows=2, cols=1, subplot_titles=('å®Œæ•´è§†å›¾', 'é¢„æµ‹è¯¦æƒ…'))\n",
    "\n",
    "                        # å†å²æ•°æ®ï¼ˆæœ€è¿‘180å¤©ï¼‰\n",
    "                        recent_data = data.tail(180)\n",
    "                        fig.add_trace(go.Scatter(\n",
    "                            x=recent_data.index, y=recent_data['æ”¶ç›˜'],\n",
    "                            mode='lines', name='å†å²ä»·æ ¼',\n",
    "                            line=dict(color='blue', width=2)\n",
    "                        ), row=1, col=1)\n",
    "\n",
    "                        # æœªæ¥é¢„æµ‹\n",
    "                        fig.add_trace(go.Scatter(\n",
    "                            x=future_dates, y=future_predictions,\n",
    "                            mode='lines+markers', name='æœªæ¥é¢„æµ‹',\n",
    "                            line=dict(color='red', width=2, dash='dash')\n",
    "                        ), row=1, col=1)\n",
    "\n",
    "                        fig.add_vline(x=last_date, line_dash=\"dash\", line_color=\"gray\", row=1, col=1)\n",
    "\n",
    "                        # é¢„æµ‹è¯¦æƒ…\n",
    "                        fig.add_trace(go.Scatter(\n",
    "                            x=future_dates, y=future_predictions,\n",
    "                            mode='lines+markers+text', name='é¢„æµ‹ä»·æ ¼',\n",
    "                            line=dict(color='red', width=3),\n",
    "                            text=[f'{price:.2f}' for price in future_predictions],\n",
    "                            textposition=\"top center\"\n",
    "                        ), row=2, col=1)\n",
    "\n",
    "                        fig.update_layout(\n",
    "                            title=f'{predict_stock} æœªæ¥{predict_days}å¤©ä»·æ ¼é¢„æµ‹',\n",
    "                            height=600,\n",
    "                            showlegend=True\n",
    "                        )\n",
    "\n",
    "                        fig.update_xaxes(title_text=\"æ—¥æœŸ\", row=2, col=1)\n",
    "                        fig.update_yaxes(title_text=\"ä»·æ ¼ï¼ˆå…ƒï¼‰\", row=1, col=1)\n",
    "                        fig.update_yaxes(title_text=\"ä»·æ ¼ï¼ˆå…ƒï¼‰\", row=2, col=1)\n",
    "\n",
    "                        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "                        # æ˜¾ç¤ºé¢„æµ‹æ•°æ®è¡¨\n",
    "                        st.subheader(\"é¢„æµ‹æ•°æ®\")\n",
    "                        prediction_df = pd.DataFrame({\n",
    "                            'æ—¥æœŸ': future_dates,\n",
    "                            'é¢„æµ‹ä»·æ ¼': future_predictions\n",
    "                        })\n",
    "                        st.dataframe(prediction_df.style.format({'é¢„æµ‹ä»·æ ¼': '{:.2f}'}))\n",
    "        else:\n",
    "            st.error(\"è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–è¾“å…¥è‚¡ç¥¨ä»£ç \")\n",
    "\n",
    "with tab4:\n",
    "    st.header(\"é‡åŒ–ç­–ç•¥å›æµ‹\")\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        st.subheader(\"å›æµ‹å‚æ•°\")\n",
    "        backtest_stock = st.text_input(\"å›æµ‹è‚¡ç¥¨ä»£ç \", value=\"000001\")\n",
    "\n",
    "        # ç­–ç•¥é€‰æ‹©\n",
    "        strategy_type = st.selectbox(\n",
    "            \"é€‰æ‹©å›æµ‹ç­–ç•¥\",\n",
    "            [\"simple\", \"rsi_based\", \"ma_crossover\", \"combined\", \"momentum\"],\n",
    "            format_func=lambda x: {\n",
    "                \"simple\": \"ç®€å•é¢„æµ‹ç­–ç•¥\",\n",
    "                \"rsi_based\": \"RSIç­–ç•¥\",\n",
    "                \"ma_crossover\": \"ç§»åŠ¨å¹³å‡çº¿ç­–ç•¥\",\n",
    "                \"combined\": \"ç»¼åˆç­–ç•¥\",\n",
    "                \"momentum\": \"åŠ¨é‡ç­–ç•¥\"\n",
    "            }[x]\n",
    "        )\n",
    "\n",
    "        initial_capital = st.number_input(\"åˆå§‹èµ„é‡‘ï¼ˆå…ƒï¼‰\", min_value=10000, max_value=1000000, value=100000, step=10000)\n",
    "        transaction_cost = st.slider(\"äº¤æ˜“æˆæœ¬ï¼ˆ%ï¼‰\", min_value=0.0, max_value=0.5, value=0.1, step=0.05) / 100\n",
    "\n",
    "        # ç­–ç•¥ç‰¹å®šå‚æ•°\n",
    "        if strategy_type in [\"rsi_based\", \"combined\"]:\n",
    "            col1a, col1b = st.columns(2)\n",
    "            with col1a:\n",
    "                rsi_oversold = st.slider(\"RSIè¶…å–çº¿\", min_value=10, max_value=40, value=30)\n",
    "            with col1b:\n",
    "                rsi_overbought = st.slider(\"RSIè¶…ä¹°çº¿\", min_value=60, max_value=90, value=70)\n",
    "\n",
    "        if strategy_type in [\"ma_crossover\", \"combined\"]:\n",
    "            col2a, col2b = st.columns(2)\n",
    "            with col2a:\n",
    "                ma_short = st.slider(\"çŸ­æœŸå‡çº¿\", min_value=3, max_value=20, value=5)\n",
    "            with col2b:\n",
    "                ma_long = st.slider(\"é•¿æœŸå‡çº¿\", min_value=10, max_value=50, value=20)\n",
    "\n",
    "        # é£é™©æ§åˆ¶å‚æ•°\n",
    "        col3a, col3b = st.columns(2)\n",
    "        with col3a:\n",
    "            stop_loss = st.slider(\"æ­¢æŸæ¯”ä¾‹ï¼ˆ%ï¼‰\", min_value=1.0, max_value=20.0, value=5.0, step=0.5) / 100\n",
    "        with col3b:\n",
    "            take_profit = st.slider(\"æ­¢ç›ˆæ¯”ä¾‹ï¼ˆ%ï¼‰\", min_value=5.0, max_value=50.0, value=10.0, step=1.0) / 100\n",
    "\n",
    "    with col2:\n",
    "        st.subheader(\"ç­–ç•¥è¯´æ˜\")\n",
    "        strategy_descriptions = {\n",
    "            \"simple\": \"åŸºäºé¢„æµ‹ä»·æ ¼æ–¹å‘è¿›è¡Œä¹°å–çš„ç®€å•ç­–ç•¥\",\n",
    "            \"rsi_based\": \"ç»“åˆRSIè¶…ä¹°è¶…å–å’Œé¢„æµ‹ä¿¡å·çš„ç­–ç•¥\",\n",
    "            \"ma_crossover\": \"åŸºäºç§»åŠ¨å¹³å‡çº¿äº¤å‰å’Œé¢„æµ‹ä¿¡å·çš„ç­–ç•¥\",\n",
    "            \"combined\": \"ç»¼åˆå¤šç§æŠ€æœ¯æŒ‡æ ‡å’Œé¢„æµ‹ä¿¡å·çš„ç­–ç•¥\",\n",
    "            \"momentum\": \"åŸºäºä»·æ ¼åŠ¨é‡å’Œé¢„æµ‹ä¿¡å·çš„ç­–ç•¥\"\n",
    "        }\n",
    "        st.info(strategy_descriptions.get(strategy_type, \"\"))\n",
    "\n",
    "        st.subheader(\"é£é™©æç¤º\")\n",
    "        st.warning(\"\"\"\n",
    "        - å›æµ‹ç»“æœåŸºäºå†å²æ•°æ®ï¼Œä¸ä»£è¡¨æœªæ¥è¡¨ç°\n",
    "        - å®é™…äº¤æ˜“ä¸­åº”è€ƒè™‘æ›´å¤šå› ç´ \n",
    "        - æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…\n",
    "        \"\"\")\n",
    "\n",
    "    if st.button(\"å¼€å§‹å›æµ‹\", type=\"primary\"):\n",
    "        if backtest_stock.strip() and st.session_state.model_trained:\n",
    "            with st.spinner(\"æ­£åœ¨è¿›è¡Œå›æµ‹...\"):\n",
    "                # è·å–æ•°æ®\n",
    "                data, info = st.session_state.predictor.get_stock_data(backtest_stock)\n",
    "                if data is None:\n",
    "                    st.error(f\"æ— æ³•è·å–è‚¡ç¥¨ {backtest_stock} çš„æ•°æ®\")\n",
    "                else:\n",
    "                    st.success(info)\n",
    "\n",
    "                    # è¿›è¡Œé¢„æµ‹\n",
    "                    predictions, true_values = st.session_state.predictor.predict(data)\n",
    "\n",
    "                    if predictions is not None:\n",
    "                        # æ‰§è¡Œå›æµ‹\n",
    "                        backtest_result, message = st.session_state.predictor.backtest_strategy(\n",
    "                            data, predictions, strategy_type, initial_capital, transaction_cost,\n",
    "                            rsi_oversold, rsi_overbought, ma_short, ma_long, stop_loss, take_profit\n",
    "                        )\n",
    "\n",
    "                        if backtest_result:\n",
    "                            st.success(message)\n",
    "\n",
    "                            # æ˜¾ç¤ºå›æµ‹ç»“æœ\n",
    "                            st.subheader(\"å›æµ‹ç»“æœ\")\n",
    "\n",
    "                            col1, col2, col3, col4 = st.columns(4)\n",
    "                            col1.metric(\"ç­–ç•¥æ€»æ”¶ç›Š\", f\"{backtest_result['total_return']:.2f}%\")\n",
    "                            col2.metric(\"å¹´åŒ–æ”¶ç›Š\", f\"{backtest_result['annual_return']:.2f}%\")\n",
    "                            col3.metric(\"ä¹°å…¥æŒæœ‰æ”¶ç›Š\", f\"{backtest_result['buy_hold_return']:.2f}%\")\n",
    "                            col4.metric(\"èƒœç‡\", f\"{backtest_result['win_rate']:.2f}%\")\n",
    "\n",
    "                            col1, col2, col3, col4 = st.columns(4)\n",
    "                            col1.metric(\"æœ€å¤§å›æ’¤\", f\"{backtest_result['max_drawdown']:.2f}%\")\n",
    "                            col2.metric(\"å¤æ™®æ¯”ç‡\", f\"{backtest_result['sharpe_ratio']:.2f}\")\n",
    "                            col3.metric(\"äº¤æ˜“æ¬¡æ•°\", f\"{backtest_result['total_trades']}\")\n",
    "                            strategy_name = {\n",
    "                                \"simple\": \"ç®€å•é¢„æµ‹\",\n",
    "                                \"rsi_based\": \"RSIç­–ç•¥\",\n",
    "                                \"ma_crossover\": \"å‡çº¿ç­–ç•¥\",\n",
    "                                \"combined\": \"ç»¼åˆç­–ç•¥\",\n",
    "                                \"momentum\": \"åŠ¨é‡ç­–ç•¥\"\n",
    "                            }.get(backtest_result['strategy_type'], backtest_result['strategy_type'])\n",
    "                            col4.metric(\"ç­–ç•¥ç±»å‹\", strategy_name)\n",
    "\n",
    "                            # ç»˜åˆ¶å›æµ‹ç»“æœ\n",
    "                            if len(backtest_result['dates']) > 0 and len(backtest_result['portfolio_values']) > 0:\n",
    "                                fig = go.Figure()\n",
    "\n",
    "                                # ç­–ç•¥å‡€å€¼æ›²çº¿\n",
    "                                fig.add_trace(go.Scatter(\n",
    "                                    x=backtest_result['dates'],\n",
    "                                    y=backtest_result['portfolio_values'],\n",
    "                                    mode='lines',\n",
    "                                    name='ç­–ç•¥å‡€å€¼',\n",
    "                                    line=dict(color='blue', width=2)\n",
    "                                ))\n",
    "\n",
    "                                # ä¹°å…¥æŒæœ‰å‡€å€¼æ›²çº¿\n",
    "                                buy_hold_values = [initial_capital * (\n",
    "                                            1 + backtest_result['buy_hold_return'] / 100 * i / len(\n",
    "                                        backtest_result['dates']))\n",
    "                                                   for i in range(len(backtest_result['dates']))]\n",
    "                                fig.add_trace(go.Scatter(\n",
    "                                    x=backtest_result['dates'],\n",
    "                                    y=buy_hold_values,\n",
    "                                    mode='lines',\n",
    "                                    name='ä¹°å…¥æŒæœ‰',\n",
    "                                    line=dict(color='green', width=2, dash='dash')\n",
    "                                ))\n",
    "\n",
    "                                # æ ‡è®°äº¤æ˜“ç‚¹\n",
    "                                buy_dates = []\n",
    "                                buy_prices = []\n",
    "                                sell_dates = []\n",
    "                                sell_prices = []\n",
    "\n",
    "                                for trade in backtest_result['trades']:\n",
    "                                    if trade[0] == 'BUY':\n",
    "                                        buy_dates.append(trade[1])\n",
    "                                        buy_prices.append(trade[2])\n",
    "                                    elif trade[0] == 'SELL':\n",
    "                                        sell_dates.append(trade[1])\n",
    "                                        sell_prices.append(trade[2])\n",
    "\n",
    "                                if buy_dates:\n",
    "                                    fig.add_trace(go.Scatter(\n",
    "                                        x=buy_dates,\n",
    "                                        y=buy_prices,\n",
    "                                        mode='markers',\n",
    "                                        name='ä¹°å…¥ç‚¹',\n",
    "                                        marker=dict(color='green', size=10, symbol='triangle-up')\n",
    "                                    ))\n",
    "\n",
    "                                if sell_dates:\n",
    "                                    fig.add_trace(go.Scatter(\n",
    "                                        x=sell_dates,\n",
    "                                        y=sell_prices,\n",
    "                                        mode='markers',\n",
    "                                        name='å–å‡ºç‚¹',\n",
    "                                        marker=dict(color='red', size=10, symbol='triangle-down')\n",
    "                                    ))\n",
    "\n",
    "                                fig.update_layout(\n",
    "                                    title=f'{backtest_stock} {strategy_name}å›æµ‹ç»“æœ',\n",
    "                                    xaxis_title='æ—¥æœŸ',\n",
    "                                    yaxis_title='æŠ•èµ„ç»„åˆä»·å€¼ï¼ˆå…ƒï¼‰',\n",
    "                                    hovermode='x unified',\n",
    "                                    height=500\n",
    "                                )\n",
    "\n",
    "                                st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "                                # æ˜¾ç¤ºæŠ€æœ¯æŒ‡æ ‡å›¾è¡¨\n",
    "                                st.subheader(\"æŠ€æœ¯æŒ‡æ ‡\")\n",
    "                                tech_fig = make_subplots(rows=2, cols=1, subplot_titles=('ä»·æ ¼ä¸å‡çº¿', 'RSIæŒ‡æ ‡'))\n",
    "\n",
    "                                # ä»·æ ¼å’Œå‡çº¿\n",
    "                                tech_fig.add_trace(go.Scatter(\n",
    "                                    x=data.index,\n",
    "                                    y=data['æ”¶ç›˜'],\n",
    "                                    mode='lines',\n",
    "                                    name='æ”¶ç›˜ä»·',\n",
    "                                    line=dict(color='black', width=1)\n",
    "                                ), row=1, col=1)\n",
    "\n",
    "                                if 'MA5' in data.columns:\n",
    "                                    tech_fig.add_trace(go.Scatter(\n",
    "                                        x=data.index,\n",
    "                                        y=data['MA5'],\n",
    "                                        mode='lines',\n",
    "                                        name='MA5',\n",
    "                                        line=dict(color='blue', width=1)\n",
    "                                    ), row=1, col=1)\n",
    "\n",
    "                                if 'MA20' in data.columns:\n",
    "                                    tech_fig.add_trace(go.Scatter(\n",
    "                                        x=data.index,\n",
    "                                        y=data['MA20'],\n",
    "                                        mode='lines',\n",
    "                                        name='MA20',\n",
    "                                        line=dict(color='red', width=1)\n",
    "                                    ), row=1, col=1)\n",
    "\n",
    "                                # RSI\n",
    "                                if 'RSI' in data.columns:\n",
    "                                    tech_fig.add_trace(go.Scatter(\n",
    "                                        x=data.index,\n",
    "                                        y=data['RSI'],\n",
    "                                        mode='lines',\n",
    "                                        name='RSI',\n",
    "                                        line=dict(color='purple', width=1)\n",
    "                                    ), row=2, col=1)\n",
    "\n",
    "                                    # æ·»åŠ è¶…ä¹°è¶…å–çº¿\n",
    "                                    tech_fig.add_hline(y=70, line_dash=\"dash\", line_color=\"red\", row=2, col=1)\n",
    "                                    tech_fig.add_hline(y=30, line_dash=\"dash\", line_color=\"green\", row=2, col=1)\n",
    "\n",
    "                                tech_fig.update_layout(height=600, showlegend=True)\n",
    "                                tech_fig.update_yaxes(title_text=\"ä»·æ ¼\", row=1, col=1)\n",
    "                                tech_fig.update_yaxes(title_text=\"RSI\", row=2, col=1)\n",
    "\n",
    "                                st.plotly_chart(tech_fig, use_container_width=True)\n",
    "                            else:\n",
    "                                st.warning(\"å›æµ‹æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨\")\n",
    "\n",
    "                            # æ˜¾ç¤ºäº¤æ˜“è®°å½•\n",
    "                            if backtest_result['trades']:\n",
    "                                st.subheader(\"äº¤æ˜“è®°å½•\")\n",
    "                                trades_df = pd.DataFrame(backtest_result['trades'],\n",
    "                                                         columns=['æ“ä½œ', 'æ—¥æœŸ', 'ä»·æ ¼', 'å¤‡æ³¨'])\n",
    "                                st.dataframe(trades_df.style.format({'ä»·æ ¼': '{:.2f}'}))\n",
    "                        else:\n",
    "                            st.error(message)\n",
    "        else:\n",
    "            st.error(\"è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–è¾“å…¥è‚¡ç¥¨ä»£ç \")\n",
    "\n",
    "with tab5:\n",
    "    st.header(\"æ¨¡å‹ç®¡ç†\")\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        st.subheader(\"ä¿å­˜æ¨¡å‹\")\n",
    "        save_path = st.text_input(\"æ¨¡å‹ä¿å­˜è·¯å¾„\", value=\"saved_models/stock_predictor\",\n",
    "                                  help=\"è¯·è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¾‹å¦‚: saved_models/my_model\")\n",
    "\n",
    "        st.info(\"\"\"\n",
    "        **ä¿å­˜è¯´æ˜:**\n",
    "        - æ¨¡å‹å°†ä¿å­˜ä¸ºä¸€ä¸ªæ–‡ä»¶å¤¹å’Œä¸€ä¸ªé…ç½®æ–‡ä»¶\n",
    "        - ä¾‹å¦‚: è¾“å…¥ `saved_models/my_model` å°†åˆ›å»º:\n",
    "          - `saved_models/my_model/` (æ¨¡å‹æ–‡ä»¶å¤¹)\n",
    "          - `saved_models/my_model_config.pkl` (é…ç½®æ–‡ä»¶)\n",
    "        \"\"\")\n",
    "\n",
    "        if st.button(\"ä¿å­˜æ¨¡å‹\", type=\"primary\"):\n",
    "            if st.session_state.model_trained:\n",
    "                success, message = st.session_state.predictor.save_model(save_path)\n",
    "                if success:\n",
    "                    st.success(message)\n",
    "                else:\n",
    "                    st.error(message)\n",
    "            else:\n",
    "                st.error(\"æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹å¯ä¿å­˜\")\n",
    "\n",
    "    with col2:\n",
    "        st.subheader(\"åŠ è½½æ¨¡å‹\")\n",
    "        load_path = st.text_input(\"æ¨¡å‹åŠ è½½è·¯å¾„\", value=\"saved_models/stock_predictor\",\n",
    "                                  help=\"è¯·è¾“å…¥æ¨¡å‹æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¾‹å¦‚: saved_models/my_model\")\n",
    "\n",
    "        st.info(\"\"\"\n",
    "        **åŠ è½½è¯´æ˜:**\n",
    "        - è¯·è¾“å…¥æ¨¡å‹æ–‡ä»¶å¤¹çš„è·¯å¾„\n",
    "        - ä¾‹å¦‚: è¾“å…¥ `saved_models/my_model` å°†åŠ è½½:\n",
    "          - `saved_models/my_model/` (æ¨¡å‹æ–‡ä»¶å¤¹)\n",
    "          - `saved_models/my_model_config.pkl` (é…ç½®æ–‡ä»¶)\n",
    "        - è¯·ç¡®ä¿è¿™ä¸¤ä¸ªæ–‡ä»¶éƒ½å­˜åœ¨\n",
    "        \"\"\")\n",
    "\n",
    "        # æ˜¾ç¤ºå½“å‰ç›®å½•ä¸‹çš„æ¨¡å‹æ–‡ä»¶\n",
    "        if st.button(\"æŸ¥çœ‹å¯ç”¨æ¨¡å‹\"):\n",
    "            model_dirs = []\n",
    "            if os.path.exists(\"saved_models\"):\n",
    "                for item in os.listdir(\"saved_models\"):\n",
    "                    item_path = os.path.join(\"saved_models\", item)\n",
    "                    if os.path.isdir(item_path):\n",
    "                        config_file = os.path.join(\"saved_models\", f\"{item}_config.pkl\")\n",
    "                        if os.path.exists(config_file):\n",
    "                            model_dirs.append(item)\n",
    "\n",
    "            if model_dirs:\n",
    "                st.write(\"å¯ç”¨çš„æ¨¡å‹:\")\n",
    "                for model_dir in model_dirs:\n",
    "                    st.write(f\"- saved_models/{model_dir}\")\n",
    "            else:\n",
    "                st.write(\"æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹\")\n",
    "\n",
    "        if st.button(\"åŠ è½½æ¨¡å‹\", type=\"primary\"):\n",
    "            success, message = st.session_state.predictor.load_model(load_path)\n",
    "            if success:\n",
    "                st.session_state.model_trained = True\n",
    "                st.success(message)\n",
    "            else:\n",
    "                st.error(message)\n",
    "\n",
    "    # æ¨¡å‹ä¿¡æ¯\n",
    "    st.subheader(\"æ¨¡å‹ä¿¡æ¯\")\n",
    "    if st.session_state.model_trained:\n",
    "        st.success(\"âœ… æ¨¡å‹å·²åŠ è½½\")\n",
    "        st.write(f\"- æ¨¡å‹ç±»å‹: {st.session_state.predictor.model_type}\")\n",
    "        st.write(f\"- æ—¶é—´çª—å£: {st.session_state.predictor.time_window}å¤©\")\n",
    "        st.write(f\"- è¾“å…¥ç‰¹å¾: {', '.join(st.session_state.predictor.features)}\")\n",
    "        if st.session_state.training_history:\n",
    "            st.write(f\"- æœ€ç»ˆè®­ç»ƒæŸå¤±: {st.session_state.training_history.history['loss'][-1]:.4f}\")\n",
    "            st.write(f\"- æœ€ç»ˆéªŒè¯æŸå¤±: {st.session_state.training_history.history['val_loss'][-1]:.4f}\")\n",
    "    else:\n",
    "        st.warning(\"â³ æ¨¡å‹æœªåŠ è½½\")\n",
    "\n",
    "    # æ•°æ®ç¼“å­˜ç®¡ç†\n",
    "    st.subheader(\"æ•°æ®ç¼“å­˜ç®¡ç†\")\n",
    "    if st.button(\"æ¸…é™¤æ•°æ®ç¼“å­˜\"):\n",
    "        cache_dir = \"stock_data_cache\"\n",
    "        if os.path.exists(cache_dir):\n",
    "            for file in os.listdir(cache_dir):\n",
    "                file_path = os.path.join(cache_dir, file)\n",
    "                try:\n",
    "                    if os.path.isfile(file_path):\n",
    "                        os.unlink(file_path)\n",
    "                except Exception as e:\n",
    "                    st.error(f\"åˆ é™¤æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}\")\n",
    "            st.success(\"æ•°æ®ç¼“å­˜å·²æ¸…é™¤\")\n",
    "        else:\n",
    "            st.info(\"æ•°æ®ç¼“å­˜ç›®å½•ä¸å­˜åœ¨\")\n",
    "\n",
    "# é¡µè„š\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <div style='text-align: center'>\n",
    "        <p>ğŸ“Š æ™ºèƒ½è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ | åŸºäºæ·±åº¦å­¦ä¹ çš„æ—¶é—´åºåˆ—é¢„æµ‹ä¸é‡åŒ–å›æµ‹</p>\n",
    "        <p><small>æ³¨æ„ï¼šæœ¬ç³»ç»Ÿé¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚</small></p>\n",
    "    </div>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    ")\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'akshare'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcallbacks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EarlyStopping, Callback\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01makshare\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mak\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpickle\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'akshare'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "26975ba7cbbcc62e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
