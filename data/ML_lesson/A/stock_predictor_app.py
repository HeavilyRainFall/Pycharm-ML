import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import tensorflow as tf
from tensorflow.keras.layers import Input, LSTM, Dense, MultiHeadAttention, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
import akshare as ak
import warnings
import pickle
import os
from datetime import datetime, timedelta
import json

warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)


class StockPredictor:
    def __init__(self, time_window=30):
        self.time_window = time_window
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        self.model = None
        self.features = ["å¼€ç›˜", "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡"]
        self.close_idx = self.features.index("æ”¶ç›˜")
        self.is_trained = False

    def get_stock_data(self, stock_code, start_date="20200101", end_date=None):
        """è·å–è‚¡ç¥¨æ•°æ®"""
        if end_date is None:
            end_date = datetime.now().strftime("%Y%m%d")

        try:
            df = ak.stock_zh_a_hist(
                symbol=stock_code,
                period="daily",
                start_date=start_date,
                end_date=end_date,
                adjust="qfq"
            )

            if df is not None and len(df) > 0:
                # æ•°æ®é¢„å¤„ç†
                df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
                df = df.sort_values("æ—¥æœŸ")
                df.set_index("æ—¥æœŸ", inplace=True)

                # é€‰æ‹©ç‰¹å¾
                available_features = [col for col in self.features if col in df.columns]
                data = df[available_features].dropna()

                return data, f"æˆåŠŸè·å–è‚¡ç¥¨ {stock_code} æ•°æ®ï¼Œå…± {len(data)} è¡Œ"
            else:
                return None, f"è‚¡ç¥¨ {stock_code} è¿”å›ç©ºæ•°æ®"

        except Exception as e:
            return None, f"è·å–è‚¡ç¥¨ {stock_code} æ—¶å‡ºé”™: {e}"

    def create_simulated_data(self, stock_name="æ¨¡æ‹Ÿè‚¡ç¥¨", start_date="2020-01-01", end_date=None):
        """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•"""
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        dates = pd.date_range(start=start_date, end=end_date, freq='D')
        np.random.seed(42)

        n = len(dates)
        trend = np.linspace(100, 200, n)
        noise = np.cumsum(np.random.randn(n) * 0.8)
        price = trend + noise

        df = pd.DataFrame({
            'å¼€ç›˜': price + np.random.randn(n) * 2,
            'æœ€é«˜': price + np.abs(np.random.randn(n)) * 3 + 2,
            'æœ€ä½': price - np.abs(np.random.randn(n)) * 3 - 2,
            'æ”¶ç›˜': price,
            'æˆäº¤é‡': np.random.randint(1000000, 20000000, n) + np.cumsum(np.random.randn(n) * 1000000).astype(int)
        }, index=dates)

        return df, f"åˆ›å»º {stock_name} æ¨¡æ‹Ÿæ•°æ®ï¼Œå…± {len(df)} è¡Œ"

    def prepare_data(self, data):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        scaled_data = self.scaler.fit_transform(data)

        def create_sequences(data, time_window, target_idx):
            X, y = [], []
            for i in range(time_window, len(data)):
                X.append(data[i - time_window:i])
                y.append(data[i, target_idx])
            return np.array(X), np.array(y)

        train_size = int(len(scaled_data) * 0.8)
        train_data = scaled_data[:train_size]
        test_data = scaled_data[train_size:]

        train_X, train_y = create_sequences(train_data, self.time_window, self.close_idx)
        test_X, test_y = create_sequences(test_data, self.time_window, self.close_idx)

        return train_X, train_y, test_X, test_y, train_size

    def build_model(self, input_shape):
        """æ„å»ºLSTM+Attentionæ¨¡å‹"""
        inputs = Input(shape=input_shape)
        lstm_out = LSTM(64, return_sequences=True, activation='tanh')(inputs)
        lstm_out = Dropout(0.2)(lstm_out)

        attention_out = MultiHeadAttention(num_heads=4, key_dim=32)(lstm_out, lstm_out)
        combined = lstm_out + attention_out

        last_step = combined[:, -1, :]
        output = Dense(32, activation='relu')(last_step)
        output = Dropout(0.2)(output)
        output = Dense(1, activation='linear')(output)

        model = Model(inputs=inputs, outputs=output)
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='mean_squared_error',
            metrics=['mae']
        )
        return model

    def train_model(self, stock_codes, epochs=50, use_simulated=False):
        """è®­ç»ƒæ¨¡å‹"""
        all_train_X, all_train_y = [], []
        all_test_X, all_test_y = [], []
        stock_data_info = []

        if not isinstance(stock_codes, list):
            stock_codes = [stock_codes]

        for stock_code in stock_codes:
            if use_simulated:
                data, info = self.create_simulated_data(stock_code)
            else:
                data, info = self.get_stock_data(stock_code)
                if data is None:
                    data, info = self.create_simulated_data(stock_code)

            stock_data_info.append(f"{stock_code}: {info}")

            train_X, train_y, test_X, test_y, _ = self.prepare_data(data)

            all_train_X.append(train_X)
            all_train_y.append(train_y)
            all_test_X.append(test_X)
            all_test_y.append(test_y)

        # åˆå¹¶æ•°æ®
        train_X = np.vstack(all_train_X)
        train_y = np.hstack(all_train_y)
        test_X = np.vstack(all_test_X)
        test_y = np.hstack(all_test_y)

        # æ„å»ºæ¨¡å‹
        self.model = self.build_model((self.time_window, len(self.features)))

        # è®­ç»ƒæ¨¡å‹
        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

        history = self.model.fit(
            train_X, train_y,
            epochs=epochs,
            batch_size=32,
            validation_data=(test_X, test_y),
            verbose=0,
            callbacks=[early_stopping]
        )

        self.is_trained = True

        return history, train_X, train_y, test_X, test_y, stock_data_info

    def predict(self, data):
        """å¯¹ç»™å®šæ•°æ®è¿›è¡Œé¢„æµ‹"""
        if not self.is_trained:
            return None, "æ¨¡å‹æœªè®­ç»ƒ"

        scaled_data = self.scaler.transform(data)

        X, y = [], []
        for i in range(self.time_window, len(scaled_data)):
            X.append(scaled_data[i - self.time_window:i])
            y.append(scaled_data[i, self.close_idx])

        X, y = np.array(X), np.array(y)

        predictions = self.model.predict(X, verbose=0)

        # åå½’ä¸€åŒ–
        predictions_inv = self.inverse_transform_pred(predictions)
        y_inv = self.inverse_transform_pred(y.reshape(-1, 1))

        return predictions_inv, y_inv

    def predict_future(self, data, days=30):
        """é¢„æµ‹æœªæ¥ä»·æ ¼èµ°åŠ¿"""
        if not self.is_trained:
            return None, "æ¨¡å‹æœªè®­ç»ƒ"

        last_sequence = data[-self.time_window:]
        last_sequence_scaled = self.scaler.transform(last_sequence)

        future_predictions = []
        current_sequence = last_sequence_scaled.copy()

        for _ in range(days):
            next_pred = self.model.predict(current_sequence.reshape(1, self.time_window, len(self.features)), verbose=0)
            future_predictions.append(next_pred[0, 0])

            new_day = current_sequence[-1].copy()
            new_day[self.close_idx] = next_pred[0, 0]
            current_sequence = np.vstack([current_sequence[1:], new_day])

        future_predictions = self.inverse_transform_pred(np.array(future_predictions).reshape(-1, 1))

        return future_predictions

    def inverse_transform_pred(self, y_pred):
        """åå½’ä¸€åŒ–é¢„æµ‹ç»“æœ"""
        y_reshaped = np.zeros(shape=(len(y_pred), len(self.features)))
        y_reshaped[:, self.close_idx] = y_pred.flatten()
        return self.scaler.inverse_transform(y_reshaped)[:, self.close_idx]

    def evaluate_model(self, true_values, predictions):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        mae = mean_absolute_error(true_values, predictions)
        mse = mean_squared_error(true_values, predictions)
        rmse = np.sqrt(mse)
        r2 = r2_score(true_values, predictions)

        # è®¡ç®—æ–¹å‘å‡†ç¡®ç‡
        if len(true_values) > 1:
            true_direction = np.diff(true_values) > 0
            pred_direction = np.diff(predictions) > 0
            direction_accuracy = np.mean(true_direction == pred_direction) * 100
        else:
            direction_accuracy = 0

        return {
            'MAE': mae,
            'RMSE': rmse,
            'R2': r2,
            'Direction_Accuracy': direction_accuracy
        }

    def save_model(self, filepath):
        """ä¿å­˜æ¨¡å‹å’Œé…ç½®"""
        if self.model is None:
            return False, "æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹å¯ä¿å­˜"

        # åˆ›å»ºç›®å½•
        os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)

        # ä¿å­˜æ¨¡å‹
        model_path = filepath if filepath.endswith('.h5') else filepath + '.h5'
        self.model.save(model_path)

        # ä¿å­˜scalerå’Œå…¶ä»–é…ç½®
        config = {
            'time_window': self.time_window,
            'features': self.features,
            'close_idx': self.close_idx,
            'is_trained': self.is_trained,
            'scaler_params': {
                'min_': self.scaler.min_,
                'scale_': self.scaler.scale_,
                'data_min_': self.scaler.data_min_,
                'data_max_': self.scaler.data_max_,
                'data_range_': self.scaler.data_range_
            }
        }

        config_path = filepath.replace('.h5', '_config.pkl') if filepath.endswith('.h5') else filepath + '_config.pkl'
        with open(config_path, 'wb') as f:
            pickle.dump(config, f)

        return True, f"æ¨¡å‹å·²ä¿å­˜åˆ° {model_path}"

    def load_model(self, filepath):
        """åŠ è½½æ¨¡å‹å’Œé…ç½®"""
        model_path = filepath if filepath.endswith('.h5') else filepath + '.h5'
        config_path = filepath.replace('.h5', '_config.pkl') if filepath.endswith('.h5') else filepath + '_config.pkl'

        if not os.path.exists(model_path) or not os.path.exists(config_path):
            return False, "æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨"

        try:
            # åŠ è½½æ¨¡å‹
            self.model = tf.keras.models.load_model(model_path)

            # åŠ è½½é…ç½®
            with open(config_path, 'rb') as f:
                config = pickle.load(f)

            self.time_window = config['time_window']
            self.features = config['features']
            self.close_idx = config['close_idx']
            self.is_trained = config['is_trained']

            # æ¢å¤scaler
            self.scaler = MinMaxScaler(feature_range=(0, 1))
            self.scaler.min_ = config['scaler_params']['min_']
            self.scaler.scale_ = config['scaler_params']['scale_']
            self.scaler.data_min_ = config['scaler_params']['data_min_']
            self.scaler.data_max_ = config['scaler_params']['data_max_']
            self.scaler.data_range_ = config['scaler_params']['data_range_']

            return True, f"æ¨¡å‹å·²ä» {model_path} åŠ è½½"

        except Exception as e:
            return False, f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}"


# åˆå§‹åŒ–é¢„æµ‹å™¨
if 'predictor' not in st.session_state:
    st.session_state.predictor = StockPredictor()
    st.session_state.model_trained = False
    st.session_state.training_history = None

# ç•Œé¢è®¾è®¡
st.title("ğŸ“ˆ æ™ºèƒ½è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ")
st.markdown("ä½¿ç”¨LSTM+Attentionç¥ç»ç½‘ç»œè¿›è¡Œå¤šè‚¡ç¥¨è®­ç»ƒå’Œé¢„æµ‹")

# ä¾§è¾¹æ 
st.sidebar.header("æ¨¡å‹é…ç½®")

# æ—¶é—´çª—å£è®¾ç½®
time_window = st.sidebar.slider("æ—¶é—´çª—å£å¤§å°", min_value=10, max_value=60, value=30, step=5)
st.session_state.predictor.time_window = time_window

# ä¸»ç•Œé¢é€‰é¡¹å¡
tab1, tab2, tab3, tab4 = st.tabs(["ğŸš€ æ¨¡å‹è®­ç»ƒ", "ğŸ” è‚¡ç¥¨éªŒè¯", "ğŸ”® æœªæ¥é¢„æµ‹", "ğŸ’¾ æ¨¡å‹ç®¡ç†"])

with tab1:
    st.header("æ¨¡å‹è®­ç»ƒ")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("è®­ç»ƒå‚æ•°")
        train_stocks = st.text_area(
            "è®­ç»ƒè‚¡ç¥¨ä»£ç ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰",
            value="600519,000858,300750",
            help="ä¾‹å¦‚ï¼š600519,000858,300750"
        )
        epochs = st.number_input("è®­ç»ƒè½®æ•° (Epochs)", min_value=10, max_value=500, value=50)
        use_simulated = st.checkbox("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆå½“çœŸå®æ•°æ®ä¸å¯ç”¨æ—¶ï¼‰", value=True)

    with col2:
        st.subheader("è®­ç»ƒçŠ¶æ€")
        if st.session_state.model_trained:
            st.success("âœ… æ¨¡å‹å·²è®­ç»ƒå®Œæˆ")
            if st.session_state.training_history:
                st.write(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {st.session_state.training_history.history['loss'][-1]:.4f}")
                st.write(f"æœ€ç»ˆéªŒè¯æŸå¤±: {st.session_state.training_history.history['val_loss'][-1]:.4f}")
        else:
            st.warning("â³ æ¨¡å‹æœªè®­ç»ƒ")

    if st.button("å¼€å§‹è®­ç»ƒæ¨¡å‹", type="primary"):
        if train_stocks.strip():
            stock_list = [s.strip() for s in train_stocks.split(',') if s.strip()]

            with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç¨å€™..."):
                progress_bar = st.progress(0)

                history, train_X, train_y, test_X, test_y, stock_info = st.session_state.predictor.train_model(
                    stock_list, epochs=epochs, use_simulated=use_simulated
                )

                st.session_state.training_history = history
                st.session_state.model_trained = True
                progress_bar.progress(100)

                # æ˜¾ç¤ºè®­ç»ƒç»“æœ
                st.success("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

                # æ˜¾ç¤ºè‚¡ç¥¨æ•°æ®ä¿¡æ¯
                st.subheader("è®­ç»ƒæ•°æ®ä¿¡æ¯")
                for info in stock_info:
                    st.write(f"- {info}")

                # ç»˜åˆ¶è®­ç»ƒå†å²
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

                ax1.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')
                ax1.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')
                ax1.set_title('æ¨¡å‹æŸå¤±')
                ax1.set_xlabel('Epoch')
                ax1.set_ylabel('Loss')
                ax1.legend()
                ax1.grid(True, alpha=0.3)

                ax2.plot(history.history['mae'], label='è®­ç»ƒMAE')
                ax2.plot(history.history['val_mae'], label='éªŒè¯MAE')
                ax2.set_title('æ¨¡å‹MAE')
                ax2.set_xlabel('Epoch')
                ax2.set_ylabel('MAE')
                ax2.legend()
                ax2.grid(True, alpha=0.3)

                st.pyplot(fig)

        else:
            st.error("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè‚¡ç¥¨ä»£ç ")

with tab2:
    st.header("è‚¡ç¥¨éªŒè¯")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("éªŒè¯å‚æ•°")
        validate_stock = st.text_input("éªŒè¯è‚¡ç¥¨ä»£ç ", value="000001")
        use_current_model = st.checkbox("ä½¿ç”¨å½“å‰è®­ç»ƒå¥½çš„æ¨¡å‹", value=True)

    with col2:
        st.subheader("éªŒè¯è¯´æ˜")
        st.info("""
        ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æ–°çš„è‚¡ç¥¨æ•°æ®è¿›è¡ŒéªŒè¯ï¼Œ
        è¯„ä¼°æ¨¡å‹åœ¨æœªè§è¿‡çš„è‚¡ç¥¨ä¸Šçš„è¡¨ç°ã€‚
        """)

    if st.button("å¼€å§‹éªŒè¯", type="primary"):
        if validate_stock.strip() and st.session_state.model_trained:
            with st.spinner("æ­£åœ¨éªŒè¯æ¨¡å‹..."):
                # è·å–éªŒè¯æ•°æ®
                data, info = st.session_state.predictor.get_stock_data(validate_stock)
                if data is None:
                    st.error(f"æ— æ³•è·å–è‚¡ç¥¨ {validate_stock} çš„æ•°æ®")
                else:
                    st.success(info)

                    # è¿›è¡Œé¢„æµ‹
                    predictions, true_values = st.session_state.predictor.predict(data)

                    if predictions is not None:
                        # è¯„ä¼°æ¨¡å‹
                        metrics = st.session_state.predictor.evaluate_model(true_values, predictions)

                        # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
                        st.subheader("éªŒè¯ç»“æœ")
                        col1, col2, col3, col4 = st.columns(4)
                        col1.metric("MAE", f"{metrics['MAE']:.4f}")
                        col2.metric("RMSE", f"{metrics['RMSE']:.4f}")
                        col3.metric("RÂ² Score", f"{metrics['R2']:.4f}")
                        col4.metric("æ–¹å‘å‡†ç¡®ç‡", f"{metrics['Direction_Accuracy']:.2f}%")

                        # ç»˜åˆ¶éªŒè¯ç»“æœ
                        train_size = int(len(data) * 0.8)
                        test_dates = data.index[train_size + time_window:]

                        fig = go.Figure()
                        fig.add_trace(go.Scatter(
                            x=test_dates, y=true_values,
                            mode='lines', name='çœŸå®ä»·æ ¼',
                            line=dict(color='blue', width=2)
                        ))
                        fig.add_trace(go.Scatter(
                            x=test_dates, y=predictions,
                            mode='lines', name='é¢„æµ‹ä»·æ ¼',
                            line=dict(color='red', width=1, dash='dash')
                        ))
                        fig.update_layout(
                            title=f'{validate_stock} éªŒè¯ç»“æœ',
                            xaxis_title='æ—¥æœŸ',
                            yaxis_title='ä»·æ ¼ï¼ˆå…ƒï¼‰',
                            hovermode='x unified'
                        )
                        st.plotly_chart(fig, use_container_width=True)
        else:
            st.error("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–è¾“å…¥è‚¡ç¥¨ä»£ç ")

with tab3:
    st.header("æœªæ¥é¢„æµ‹")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("é¢„æµ‹å‚æ•°")
        predict_stock = st.text_input("é¢„æµ‹è‚¡ç¥¨ä»£ç ", value="600519")
        predict_days = st.slider("é¢„æµ‹å¤©æ•°", min_value=5, max_value=60, value=30)
        end_date = st.date_input("æ•°æ®æˆªæ­¢æ—¥æœŸ", value=datetime.now())

    with col2:
        st.subheader("é¢„æµ‹è¯´æ˜")
        st.info("""
        åŸºäºå†å²æ•°æ®é¢„æµ‹æœªæ¥è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿ã€‚
        é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚
        """)

    if st.button("å¼€å§‹é¢„æµ‹", type="primary"):
        if predict_stock.strip() and st.session_state.model_trained:
            with st.spinner("æ­£åœ¨è¿›è¡Œé¢„æµ‹..."):
                # è·å–æ•°æ®
                end_date_str = end_date.strftime("%Y%m%d")
                data, info = st.session_state.predictor.get_stock_data(predict_stock, end_date=end_date_str)

                if data is None:
                    st.error(f"æ— æ³•è·å–è‚¡ç¥¨ {predict_stock} çš„æ•°æ®")
                else:
                    st.success(info)

                    # è¿›è¡Œæœªæ¥é¢„æµ‹
                    future_predictions = st.session_state.predictor.predict_future(data, days=predict_days)

                    if future_predictions is not None:
                        # åˆ›å»ºæœªæ¥æ—¥æœŸ
                        last_date = data.index[-1]
                        future_dates = [last_date + timedelta(days=i) for i in range(1, predict_days + 1)]

                        # ç»˜åˆ¶é¢„æµ‹ç»“æœ
                        fig = make_subplots(rows=2, cols=1, subplot_titles=('å®Œæ•´è§†å›¾', 'é¢„æµ‹è¯¦æƒ…'))

                        # å†å²æ•°æ®ï¼ˆæœ€è¿‘180å¤©ï¼‰
                        recent_data = data.tail(180)
                        fig.add_trace(go.Scatter(
                            x=recent_data.index, y=recent_data['æ”¶ç›˜'],
                            mode='lines', name='å†å²ä»·æ ¼',
                            line=dict(color='blue', width=2)
                        ), row=1, col=1)

                        # æœªæ¥é¢„æµ‹
                        fig.add_trace(go.Scatter(
                            x=future_dates, y=future_predictions,
                            mode='lines+markers', name='æœªæ¥é¢„æµ‹',
                            line=dict(color='red', width=2, dash='dash')
                        ), row=1, col=1)

                        fig.add_vline(x=last_date, line_dash="dash", line_color="gray", row=1, col=1)

                        # é¢„æµ‹è¯¦æƒ…
                        fig.add_trace(go.Scatter(
                            x=future_dates, y=future_predictions,
                            mode='lines+markers+text', name='é¢„æµ‹ä»·æ ¼',
                            line=dict(color='red', width=3),
                            text=[f'{price:.2f}' for price in future_predictions],
                            textposition="top center"
                        ), row=2, col=1)

                        fig.update_layout(
                            title=f'{predict_stock} æœªæ¥{predict_days}å¤©ä»·æ ¼é¢„æµ‹',
                            height=600,
                            showlegend=True
                        )

                        fig.update_xaxes(title_text="æ—¥æœŸ", row=2, col=1)
                        fig.update_yaxes(title_text="ä»·æ ¼ï¼ˆå…ƒï¼‰", row=1, col=1)
                        fig.update_yaxes(title_text="ä»·æ ¼ï¼ˆå…ƒï¼‰", row=2, col=1)

                        st.plotly_chart(fig, use_container_width=True)

                        # æ˜¾ç¤ºé¢„æµ‹æ•°æ®è¡¨
                        st.subheader("é¢„æµ‹æ•°æ®")
                        prediction_df = pd.DataFrame({
                            'æ—¥æœŸ': future_dates,
                            'é¢„æµ‹ä»·æ ¼': future_predictions
                        })
                        st.dataframe(prediction_df.style.format({'é¢„æµ‹ä»·æ ¼': '{:.2f}'}))
        else:
            st.error("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–è¾“å…¥è‚¡ç¥¨ä»£ç ")

with tab4:
    st.header("æ¨¡å‹ç®¡ç†")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ä¿å­˜æ¨¡å‹")
        save_path = st.text_input("æ¨¡å‹ä¿å­˜è·¯å¾„", value="saved_models/stock_predictor")

        if st.button("ä¿å­˜æ¨¡å‹", type="primary"):
            if st.session_state.model_trained:
                success, message = st.session_state.predictor.save_model(save_path)
                if success:
                    st.success(message)
                else:
                    st.error(message)
            else:
                st.error("æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹å¯ä¿å­˜")

    with col2:
        st.subheader("åŠ è½½æ¨¡å‹")
        load_path = st.text_input("æ¨¡å‹åŠ è½½è·¯å¾„", value="saved_models/stock_predictor.h5")

        if st.button("åŠ è½½æ¨¡å‹", type="primary"):
            success, message = st.session_state.predictor.load_model(load_path)
            if success:
                st.session_state.model_trained = True
                st.success(message)
            else:
                st.error(message)

    # æ¨¡å‹ä¿¡æ¯
    st.subheader("æ¨¡å‹ä¿¡æ¯")
    if st.session_state.model_trained:
        st.success("âœ… æ¨¡å‹å·²åŠ è½½")
        st.write(f"- æ—¶é—´çª—å£: {st.session_state.predictor.time_window}å¤©")
        st.write(f"- è¾“å…¥ç‰¹å¾: {', '.join(st.session_state.predictor.features)}")
        st.write(f"- æ¨¡å‹ç»“æ„: LSTM + MultiHeadAttention")
    else:
        st.warning("â³ æ¨¡å‹æœªåŠ è½½")

# é¡µè„š
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>ğŸ“Š æ™ºèƒ½è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ | åŸºäºæ·±åº¦å­¦ä¹ çš„æ—¶é—´åºåˆ—é¢„æµ‹</p>
        <p><small>æ³¨æ„ï¼šæœ¬ç³»ç»Ÿé¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚</small></p>
    </div>
    """,
    unsafe_allow_html=True
)