import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import tensorflow as tf
from tensorflow.keras.layers import Input, LSTM, Dense, MultiHeadAttention, Dropout, GRU, Conv1D, MaxPooling1D, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, Callback
import akshare as ak
import warnings
import pickle
import os
from datetime import datetime, timedelta
import json
import time
import random
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

plt.rcParams['font.sans-serif'] = ['SimHei']  # ä½¿ç”¨é»‘ä½“
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.size'] = 12  # è®¾ç½®å­—ä½“å¤§å°

warnings.filterwarnings('ignore')

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)


# é…ç½®akshareçš„è¯·æ±‚ä¼šè¯ï¼Œæ·»åŠ é‡è¯•æœºåˆ¶å’Œå»¶è¿Ÿ
def create_session():
    session = requests.Session()

    # è®¾ç½®é‡è¯•ç­–ç•¥
    retry_strategy = Retry(
        total=3,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET"],
        backoff_factor=1
    )

    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)

    # è®¾ç½®éšæœºUser-Agent
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'
    ]

    session.headers.update({
        'User-Agent': random.choice(user_agents),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    })

    return session


# å…¨å±€ä¼šè¯å¯¹è±¡
if 'ak_session' not in st.session_state:
    st.session_state.ak_session = create_session()


class TrainingProgressCallback(Callback):
    """è‡ªå®šä¹‰å›è°ƒå‡½æ•°ç”¨äºæ˜¾ç¤ºè®­ç»ƒè¿›åº¦"""

    def __init__(self, progress_bar, status_text, epochs):
        self.progress_bar = progress_bar
        self.status_text = status_text
        self.epochs = epochs

    def on_epoch_end(self, epoch, logs=None):
        progress = (epoch + 1) / self.epochs
        self.progress_bar.progress(progress)
        self.status_text.text(
            f"è®­ç»ƒè¿›åº¦: {epoch + 1}/{self.epochs} - æŸå¤±: {logs['loss']:.4f}, éªŒè¯æŸå¤±: {logs['val_loss']:.4f}")


class StockPredictor:
    def __init__(self, time_window=30):
        self.time_window = time_window
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        self.model = None
        self.features = ["å¼€ç›˜", "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡"]
        self.close_idx = self.features.index("æ”¶ç›˜")
        self.is_trained = False
        self.model_type = "LSTM+Attention"
        self.data_cache_dir = "stock_data_cache"

    def get_stock_data(self, stock_code, start_date="20200101", end_date=None):
        """è·å–è‚¡ç¥¨æ•°æ® - å¸¦æœ‰ç¼“å­˜å’Œæ›´æ–°æœºåˆ¶"""
        if end_date is None:
            end_date = datetime.now().strftime("%Y%m%d")

        # åˆ›å»ºç¼“å­˜ç›®å½•
        os.makedirs(self.data_cache_dir, exist_ok=True)

        # ç¼“å­˜æ–‡ä»¶è·¯å¾„
        cache_file = os.path.join(self.data_cache_dir, f"{stock_code}.pkl")

        # å°è¯•ä»ç¼“å­˜åŠ è½½æ•°æ®
        cached_data = None
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'rb') as f:
                    cached_data = pickle.load(f)
                st.info(f"ä»ç¼“å­˜åŠ è½½è‚¡ç¥¨ {stock_code} æ•°æ®")
            except Exception as e:
                st.warning(f"åŠ è½½ç¼“å­˜æ•°æ®å¤±è´¥: {e}")

        # å¦‚æœæœ‰ç¼“å­˜æ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        if cached_data is not None and not cached_data.empty:
            # è·å–ç¼“å­˜æ•°æ®çš„æœ€åæ—¥æœŸ
            last_cached_date = cached_data.index.max().strftime("%Y%m%d")

            # å¦‚æœç¼“å­˜æ•°æ®å·²ç»åŒ…å«æ‰€éœ€çš„æ‰€æœ‰æ—¥æœŸï¼Œç›´æ¥è¿”å›
            if last_cached_date >= end_date:
                return cached_data, f"ä»ç¼“å­˜è·å–è‚¡ç¥¨ {stock_code} æ•°æ®ï¼Œå…± {len(cached_data)} è¡Œ"

            # å¦åˆ™ï¼Œåªä¸‹è½½æ–°çš„æ•°æ®
            start_date = (pd.to_datetime(last_cached_date) + timedelta(days=1)).strftime("%Y%m%d")
            st.info(f"ç¼“å­˜æ•°æ®éœ€è¦æ›´æ–°ï¼Œä» {start_date} å¼€å§‹ä¸‹è½½æ–°æ•°æ®")

        try:
            # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            time.sleep(random.uniform(1, 3))

            # ä½¿ç”¨å¸¦æœ‰é‡è¯•æœºåˆ¶çš„akshare
            df = ak.stock_zh_a_hist(
                symbol=stock_code,
                period="daily",
                start_date=start_date,
                end_date=end_date,
                adjust="hfq"  # ä½¿ç”¨åå¤æƒæ•°æ®ï¼Œä¾¿äºé•¿æœŸåˆ†æ
            )

            if df is not None and len(df) > 0:
                # æ•°æ®é¢„å¤„ç†
                df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
                df = df.sort_values("æ—¥æœŸ")
                df.set_index("æ—¥æœŸ", inplace=True)

                # é€‰æ‹©ç‰¹å¾
                available_features = [col for col in self.features if col in df.columns]
                new_data = df[available_features].dropna()

                # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                new_data = self.add_technical_indicators(new_data)

                # åˆå¹¶ç¼“å­˜æ•°æ®å’Œæ–°æ•°æ®
                if cached_data is not None and not cached_data.empty:
                    # ç¡®ä¿æ²¡æœ‰é‡å¤æ•°æ®
                    combined_data = pd.concat([cached_data, new_data]).drop_duplicates()
                    combined_data = combined_data[~combined_data.index.duplicated(keep='last')]
                    combined_data = combined_data.sort_index()
                else:
                    combined_data = new_data

                # ä¿å­˜åˆ°ç¼“å­˜
                try:
                    with open(cache_file, 'wb') as f:
                        pickle.dump(combined_data, f)
                    st.success(f"è‚¡ç¥¨ {stock_code} æ•°æ®å·²ç¼“å­˜")
                except Exception as e:
                    st.warning(f"ä¿å­˜ç¼“å­˜æ•°æ®å¤±è´¥: {e}")

                return combined_data, f"æˆåŠŸè·å–è‚¡ç¥¨ {stock_code} æ•°æ®ï¼Œå…± {len(combined_data)} è¡Œ"
            else:
                # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œè¿”å›ç¼“å­˜æ•°æ®
                if cached_data is not None and not cached_data.empty:
                    return cached_data, f"æ— æ–°æ•°æ®ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œå…± {len(cached_data)} è¡Œ"
                else:
                    return None, f"è‚¡ç¥¨ {stock_code} è¿”å›ç©ºæ•°æ®"

        except Exception as e:
            # å¦‚æœè·å–çœŸå®æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®æˆ–æ¨¡æ‹Ÿæ•°æ®
            if cached_data is not None and not cached_data.empty:
                st.warning(f"è·å–è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨ç¼“å­˜æ•°æ®")
                return cached_data, f"ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œå…± {len(cached_data)} è¡Œ"
            else:
                st.warning(f"è·å–è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                return self.create_simulated_data(stock_code)

    def add_technical_indicators(self, data):
        """æ·»åŠ æŠ€æœ¯æŒ‡æ ‡"""
        try:
            # ç§»åŠ¨å¹³å‡çº¿
            data['MA5'] = data['æ”¶ç›˜'].rolling(window=5).mean()
            data['MA10'] = data['æ”¶ç›˜'].rolling(window=10).mean()
            data['MA20'] = data['æ”¶ç›˜'].rolling(window=20).mean()

            # æ‰‹åŠ¨è®¡ç®—RSI
            def calculate_rsi(prices, window=14):
                delta = prices.diff()
                gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
                rs = gain / loss
                rsi = 100 - (100 / (1 + rs))
                return rsi

            data['RSI'] = calculate_rsi(data['æ”¶ç›˜'])

            # æ‰‹åŠ¨è®¡ç®—MACD
            def calculate_macd(prices, fast=12, slow=26, signal=9):
                ema_fast = prices.ewm(span=fast).mean()
                ema_slow = prices.ewm(span=slow).mean()
                macd = ema_fast - ema_slow
                macd_signal = macd.ewm(span=signal).mean()
                macd_histogram = macd - macd_signal
                return macd, macd_signal, macd_histogram

            macd, macd_signal, macd_histogram = calculate_macd(data['æ”¶ç›˜'])
            data['MACD'] = macd
            data['MACD_Signal'] = macd_signal
            data['MACD_Histogram'] = macd_histogram

            # å¸ƒæ—å¸¦
            def calculate_bollinger_bands(prices, window=20, num_std=2):
                rolling_mean = prices.rolling(window=window).mean()
                rolling_std = prices.rolling(window=window).std()
                upper_band = rolling_mean + (rolling_std * num_std)
                lower_band = rolling_mean - (rolling_std * num_std)
                return upper_band, rolling_mean, lower_band

            bb_upper, bb_middle, bb_lower = calculate_bollinger_bands(data['æ”¶ç›˜'])
            data['BB_Upper'] = bb_upper
            data['BB_Middle'] = bb_middle
            data['BB_Lower'] = bb_lower

            # åˆ é™¤NaNå€¼
            data = data.dropna()

        except Exception as e:
            st.warning(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}")

        return data

    def create_simulated_data(self, stock_name="æ¨¡æ‹Ÿè‚¡ç¥¨", start_date="2020-01-01", end_date=None):
        """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•"""
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        dates = pd.date_range(start=start_date, end=end_date, freq='D')
        np.random.seed(42)

        n = len(dates)
        trend = np.linspace(100, 200, n)
        noise = np.cumsum(np.random.randn(n) * 0.8)
        price = trend + noise

        df = pd.DataFrame({
            'å¼€ç›˜': price + np.random.randn(n) * 2,
            'æœ€é«˜': price + np.abs(np.random.randn(n)) * 3 + 2,
            'æœ€ä½': price - np.abs(np.random.randn(n)) * 3 - 2,
            'æ”¶ç›˜': price,
            'æˆäº¤é‡': np.random.randint(1000000, 20000000, n) + np.cumsum(np.random.randn(n) * 1000000).astype(int)
        }, index=dates)

        # ä¸ºæ¨¡æ‹Ÿæ•°æ®æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
        df = self.add_technical_indicators(df)

        return df, f"åˆ›å»º {stock_name} æ¨¡æ‹Ÿæ•°æ®ï¼Œå…± {len(df)} è¡Œ"

    def prepare_data(self, data):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        # ä½¿ç”¨æ›´å¤šç‰¹å¾è¿›è¡Œè®­ç»ƒ
        training_features = ["å¼€ç›˜", "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡", "MA5", "MA10", "MA20", "RSI", "MACD"]
        available_features = [col for col in training_features if col in data.columns]

        if len(available_features) < 5:  # å¦‚æœæ²¡æœ‰æŠ€æœ¯æŒ‡æ ‡ï¼Œä½¿ç”¨åŸºæœ¬ç‰¹å¾
            available_features = self.features

        scaled_data = self.scaler.fit_transform(data[available_features])

        def create_sequences(data, time_window, target_idx):
            X, y = [], []
            for i in range(time_window, len(data)):
                X.append(data[i - time_window:i])
                y.append(data[i, target_idx])
            return np.array(X), np.array(y)

        train_size = int(len(scaled_data) * 0.8)
        train_data = scaled_data[:train_size]
        test_data = scaled_data[train_size:]

        # æ‰¾åˆ°æ”¶ç›˜ä»·åœ¨ç‰¹å¾ä¸­çš„ç´¢å¼•
        close_idx = available_features.index("æ”¶ç›˜") if "æ”¶ç›˜" in available_features else 3

        train_X, train_y = create_sequences(train_data, self.time_window, close_idx)
        test_X, test_y = create_sequences(test_data, self.time_window, close_idx)

        return train_X, train_y, test_X, test_y, train_size, available_features

    def build_model(self, input_shape, model_type="LSTM+Attention", lstm_units=64, gru_units=64,
                    attention_heads=4, dense_units=32, dropout_rate=0.2):
        """æ„å»ºæ¨¡å‹"""
        inputs = Input(shape=input_shape)

        if model_type == "LSTM+Attention":
            lstm_out = LSTM(lstm_units, return_sequences=True, activation='tanh')(inputs)
            lstm_out = Dropout(dropout_rate)(lstm_out)
            attention_out = MultiHeadAttention(num_heads=attention_heads, key_dim=32)(lstm_out, lstm_out)
            combined = lstm_out + attention_out
            last_step = tf.keras.layers.Lambda(lambda x: x[:, -1, :])(combined)

        elif model_type == "GRU":
            gru_out = GRU(gru_units, return_sequences=True, activation='tanh')(inputs)
            gru_out = Dropout(dropout_rate)(gru_out)
            last_step = tf.keras.layers.Lambda(lambda x: x[:, -1, :])(gru_out)

        elif model_type == "CNN+LSTM":
            # CNNéƒ¨åˆ†
            conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)
            pool1 = MaxPooling1D(pool_size=2)(conv1)
            conv2 = Conv1D(filters=32, kernel_size=3, activation='relu')(pool1)
            pool2 = MaxPooling1D(pool_size=2)(conv2)
            # LSTMéƒ¨åˆ†
            lstm_out = LSTM(lstm_units, return_sequences=False)(pool2)
            last_step = Dropout(dropout_rate)(lstm_out)

        elif model_type == "Simple LSTM":
            lstm_out = LSTM(lstm_units, return_sequences=False)(inputs)
            last_step = Dropout(dropout_rate)(lstm_out)

        else:  # é»˜è®¤LSTM+Attention
            lstm_out = LSTM(lstm_units, return_sequences=True, activation='tanh')(inputs)
            lstm_out = Dropout(dropout_rate)(lstm_out)
            attention_out = MultiHeadAttention(num_heads=attention_heads, key_dim=32)(lstm_out, lstm_out)
            combined = lstm_out + attention_out
            last_step = tf.keras.layers.Lambda(lambda x: x[:, -1, :])(combined)

        output = Dense(dense_units, activation='relu')(last_step)
        output = Dropout(dropout_rate)(output)
        output = Dense(1, activation='linear')(output)

        model = Model(inputs=inputs, outputs=output)
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='mean_squared_error',
            metrics=['mae']
        )

        self.model_type = model_type
        return model

    def train_model(self, stock_codes, epochs=50, use_simulated=False, model_type="LSTM+Attention",
                    lstm_units=64, gru_units=64, attention_heads=4, dense_units=32, dropout_rate=0.2,
                    progress_bar=None, status_text=None):
        """è®­ç»ƒæ¨¡å‹"""
        all_train_X, all_train_y = [], []
        all_test_X, all_test_y = [], []
        stock_data_info = []

        if not isinstance(stock_codes, list):
            stock_codes = [stock_codes]

        for stock_code in stock_codes:
            if use_simulated:
                data, info = self.create_simulated_data(stock_code)
            else:
                data, info = self.get_stock_data(stock_code)
                if data is None:
                    data, info = self.create_simulated_data(stock_code)

            stock_data_info.append(f"{stock_code}: {info}")

            train_X, train_y, test_X, test_y, _, features_used = self.prepare_data(data)
            self.features = features_used  # æ›´æ–°ä½¿ç”¨çš„ç‰¹å¾åˆ—è¡¨
            self.close_idx = features_used.index("æ”¶ç›˜") if "æ”¶ç›˜" in features_used else 3

            all_train_X.append(train_X)
            all_train_y.append(train_y)
            all_test_X.append(test_X)
            all_test_y.append(test_y)

        # åˆå¹¶æ•°æ®
        train_X = np.vstack(all_train_X)
        train_y = np.hstack(all_train_y)
        test_X = np.vstack(all_test_X)
        test_y = np.hstack(all_test_y)

        # æ„å»ºæ¨¡å‹
        self.model = self.build_model(
            (self.time_window, len(self.features)),
            model_type=model_type,
            lstm_units=lstm_units,
            gru_units=gru_units,
            attention_heads=attention_heads,
            dense_units=dense_units,
            dropout_rate=dropout_rate
        )

        # è®­ç»ƒæ¨¡å‹
        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

        callbacks = [early_stopping]
        if progress_bar and status_text:
            callbacks.append(TrainingProgressCallback(progress_bar, status_text, epochs))

        history = self.model.fit(
            train_X, train_y,
            epochs=epochs,
            batch_size=32,
            validation_data=(test_X, test_y),
            verbose=0,
            callbacks=callbacks
        )

        self.is_trained = True

        return history, train_X, train_y, test_X, test_y, stock_data_info

    def predict(self, data):
        """å¯¹ç»™å®šæ•°æ®è¿›è¡Œé¢„æµ‹"""
        if not self.is_trained:
            return None, "æ¨¡å‹æœªè®­ç»ƒ"

        # ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„ç‰¹å¾
        available_features = [col for col in self.features if col in data.columns]
        if len(available_features) < len(self.features):
            st.warning(f"æ•°æ®ç¼ºå°‘æŸäº›ç‰¹å¾ï¼Œä½¿ç”¨å¯ç”¨ç‰¹å¾: {available_features}")

        data_to_use = data[available_features]
        scaled_data = self.scaler.transform(data_to_use)

        X, y = [], []
        close_idx = available_features.index("æ”¶ç›˜") if "æ”¶ç›˜" in available_features else 3

        for i in range(self.time_window, len(scaled_data)):
            X.append(scaled_data[i - self.time_window:i])
            y.append(scaled_data[i, close_idx])

        X, y = np.array(X), np.array(y)

        predictions = self.model.predict(X, verbose=0)

        # åå½’ä¸€åŒ–
        predictions_inv = self.inverse_transform_pred(predictions, available_features, close_idx)
        y_inv = self.inverse_transform_pred(y.reshape(-1, 1), available_features, close_idx)

        return predictions_inv, y_inv

    def predict_future(self, data, days=30):
        """é¢„æµ‹æœªæ¥ä»·æ ¼èµ°åŠ¿"""
        if not self.is_trained:
            return None, "æ¨¡å‹æœªè®­ç»ƒ"

        # ä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„ç‰¹å¾
        available_features = [col for col in self.features if col in data.columns]
        close_idx = available_features.index("æ”¶ç›˜") if "æ”¶ç›˜" in available_features else 3

        last_sequence = data[available_features].tail(self.time_window)
        last_sequence_scaled = self.scaler.transform(last_sequence)

        future_predictions = []
        current_sequence = last_sequence_scaled.copy()

        for _ in range(days):
            next_pred = self.model.predict(current_sequence.reshape(1, self.time_window, len(available_features)),
                                           verbose=0)
            future_predictions.append(next_pred[0, 0])

            new_day = current_sequence[-1].copy()
            new_day[close_idx] = next_pred[0, 0]
            current_sequence = np.vstack([current_sequence[1:], new_day])

        future_predictions = self.inverse_transform_pred(np.array(future_predictions).reshape(-1, 1),
                                                         available_features, close_idx)

        return future_predictions

    def inverse_transform_pred(self, y_pred, features, close_idx):
        """åå½’ä¸€åŒ–é¢„æµ‹ç»“æœ"""
        y_reshaped = np.zeros(shape=(len(y_pred), len(features)))
        y_reshaped[:, close_idx] = y_pred.flatten()
        return self.scaler.inverse_transform(y_reshaped)[:, close_idx]

    def evaluate_model(self, true_values, predictions):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        mae = mean_absolute_error(true_values, predictions)
        mse = mean_squared_error(true_values, predictions)
        rmse = np.sqrt(mse)
        r2 = r2_score(true_values, predictions)

        # è®¡ç®—æ–¹å‘å‡†ç¡®ç‡
        if len(true_values) > 1:
            true_direction = np.diff(true_values) > 0
            pred_direction = np.diff(predictions) > 0
            direction_accuracy = np.mean(true_direction == pred_direction) * 100
        else:
            direction_accuracy = 0

        return {
            'MAE': mae,
            'RMSE': rmse,
            'R2': r2,
            'Direction_Accuracy': direction_accuracy
        }

    def backtest_strategy(self, data, predictions, strategy_type="simple",
                          initial_capital=100000, transaction_cost=0.001,
                          rsi_oversold=30, rsi_overbought=70,
                          ma_short=5, ma_long=20, stop_loss=0.05, take_profit=0.1):
        """
        å›æµ‹é‡åŒ–ç­–ç•¥
        æ”¯æŒå¤šç§ç­–ç•¥ç±»å‹
        """
        if len(data) != len(predictions) + self.time_window:
            return None, "æ•°æ®é•¿åº¦ä¸åŒ¹é…"

        # è·å–å®é™…ä»·æ ¼ï¼ˆä¸é¢„æµ‹å¯¹åº”çš„éƒ¨åˆ†ï¼‰
        actual_prices = data['æ”¶ç›˜'].values[self.time_window:]
        actual_dates = data.index[self.time_window:]

        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        data_with_indicators = self.add_technical_indicators(data)

        # åˆå§‹åŒ–å˜é‡
        capital = initial_capital
        position = 0  # 0è¡¨ç¤ºç©ºä»“ï¼Œ1è¡¨ç¤ºæ»¡ä»“
        shares = 0
        entry_price = 0
        trades = []
        portfolio_values = []

        # åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡å˜é‡
        rsi = 50
        ma_short_val = actual_prices[0] if len(actual_prices) > 0 else 0
        ma_long_val = actual_prices[0] if len(actual_prices) > 0 else 0

        for i in range(1, len(predictions)):
            if i >= len(actual_prices):
                break

            current_price = actual_prices[i]
            current_date = actual_dates[i]

            # è·å–æŠ€æœ¯æŒ‡æ ‡ - æ·»åŠ è¾¹ç•Œæ£€æŸ¥
            try:
                if 'RSI' in data_with_indicators.columns and self.time_window + i < len(data_with_indicators):
                    rsi = data_with_indicators['RSI'].iloc[self.time_window + i]
                else:
                    rsi = 50

                if f'MA{ma_short}' in data_with_indicators.columns and self.time_window + i < len(data_with_indicators):
                    ma_short_val = data_with_indicators[f'MA{ma_short}'].iloc[self.time_window + i]
                else:
                    ma_short_val = current_price

                if f'MA{ma_long}' in data_with_indicators.columns and self.time_window + i < len(data_with_indicators):
                    ma_long_val = data_with_indicators[f'MA{ma_long}'].iloc[self.time_window + i]
                else:
                    ma_long_val = current_price
            except (IndexError, KeyError):
                # å¦‚æœç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œä½¿ç”¨é»˜è®¤å€¼
                rsi = 50
                ma_short_val = current_price
                ma_long_val = current_price

            # é¢„æµ‹æ˜æ—¥æ¶¨è·Œ
            predicted_tomorrow = predictions[i]
            predicted_today = predictions[i - 1]
            predicted_change = (predicted_tomorrow - predicted_today) / predicted_today if predicted_today != 0 else 0

            # ç­–ç•¥å†³ç­–
            trade_signal = 0  # 0: æ— ä¿¡å·, 1: ä¹°å…¥, -1: å–å‡º

            if strategy_type == "simple":
                # ç®€å•ç­–ç•¥ï¼šåŸºäºé¢„æµ‹æ–¹å‘
                if predicted_tomorrow > predicted_today and position == 0:
                    trade_signal = 1
                elif predicted_tomorrow < predicted_today and position == 1:
                    trade_signal = -1

            elif strategy_type == "rsi_based":
                # RSIç­–ç•¥ï¼šç»“åˆRSIè¶…ä¹°è¶…å–
                if rsi < rsi_oversold and predicted_change > 0 and position == 0:
                    trade_signal = 1
                elif rsi > rsi_overbought and predicted_change < 0 and position == 1:
                    trade_signal = -1

            elif strategy_type == "ma_crossover":
                # ç§»åŠ¨å¹³å‡çº¿äº¤å‰ç­–ç•¥
                ma_signal = 1 if ma_short_val > ma_long_val else -1
                if ma_signal > 0 and predicted_change > 0 and position == 0:
                    trade_signal = 1
                elif ma_signal < 0 and predicted_change < 0 and position == 1:
                    trade_signal = -1

            elif strategy_type == "combined":
                # ç»¼åˆç­–ç•¥ï¼šç»“åˆå¤šç§æŒ‡æ ‡
                ma_signal = 1 if ma_short_val > ma_long_val else -1
                rsi_signal = 1 if rsi < rsi_oversold else (-1 if rsi > rsi_overbought else 0)

                buy_condition = (predicted_change > 0.01 and
                                 (ma_signal > 0 or rsi_signal > 0) and
                                 position == 0)

                sell_condition = (predicted_change < -0.01 and
                                  (ma_signal < 0 or rsi_signal < 0) and
                                  position == 1)

                if buy_condition:
                    trade_signal = 1
                elif sell_condition:
                    trade_signal = -1

            elif strategy_type == "momentum":
                # åŠ¨é‡ç­–ç•¥ï¼šåŸºäºä»·æ ¼åŠ¨é‡
                if i >= 5:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
                    price_momentum = (current_price - actual_prices[i - 5]) / actual_prices[i - 5] if actual_prices[
                                                                                                          i - 5] != 0 else 0
                else:
                    price_momentum = 0

                if price_momentum > 0.02 and predicted_change > 0.01 and position == 0:
                    trade_signal = 1
                elif price_momentum < -0.02 and predicted_change < -0.01 and position == 1:
                    trade_signal = -1

            # æ­¢æŸæ­¢ç›ˆæ£€æŸ¥
            if position == 1:
                profit_pct = (current_price - entry_price) / entry_price if entry_price != 0 else 0
                if profit_pct <= -stop_loss or profit_pct >= take_profit:
                    trade_signal = -1  # å¼ºåˆ¶å–å‡º

            # æ‰§è¡Œäº¤æ˜“
            if trade_signal == 1 and position == 0:  # ä¹°å…¥
                shares = capital / current_price
                capital = 0
                position = 1
                entry_price = current_price
                trades.append(('BUY', current_date, current_price, f"é¢„æµ‹æ¶¨å¹…: {predicted_change:.2%}"))

            elif trade_signal == -1 and position == 1:  # å–å‡º
                capital = shares * current_price * (1 - transaction_cost)
                shares = 0
                position = 0
                profit = (current_price - entry_price) / entry_price if entry_price != 0 else 0
                trades.append(('SELL', current_date, current_price, f"ç›ˆäº: {profit:.2%}"))

            # è®¡ç®—å½“å‰æŠ•èµ„ç»„åˆä»·å€¼
            if position == 1:
                portfolio_value = shares * current_price
            else:
                portfolio_value = capital

            portfolio_values.append(portfolio_value)

        # è®¡ç®—æœ€ç»ˆæ”¶ç›Š
        if position == 1:  # å¦‚æœæœ€åè¿˜æŒæœ‰è‚¡ç¥¨ï¼ŒæŒ‰æœ€åä»·æ ¼å–å‡º
            final_value = shares * actual_prices[-1] * (1 - transaction_cost)
            profit = (actual_prices[-1] - entry_price) / entry_price if entry_price != 0 else 0
            trades.append(('SELL', actual_dates[-1], actual_prices[-1], f"æœ€ç»ˆç›ˆäº: {profit:.2%}"))
        else:
            final_value = capital

        total_return = (final_value - initial_capital) / initial_capital * 100
        buy_hold_return = (actual_prices[-1] - actual_prices[0]) / actual_prices[0] * 100 if actual_prices[
                                                                                                 0] != 0 else 0

        # è®¡ç®—æœ€å¤§å›æ’¤
        if len(portfolio_values) > 0:
            portfolio_array = np.array(portfolio_values)
            peak = np.maximum.accumulate(portfolio_array)
            drawdown = (portfolio_array - peak) / peak * 100
            max_drawdown = np.min(drawdown) if len(drawdown) > 0 else 0
        else:
            max_drawdown = 0

        # è®¡ç®—å¤æ™®æ¯”ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if len(portfolio_values) > 1:
            portfolio_array = np.array(portfolio_values)
            returns = np.diff(portfolio_array) / portfolio_array[:-1]
            if len(returns) > 0 and np.std(returns) > 0:
                sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(252)
            else:
                sharpe_ratio = 0
        else:
            sharpe_ratio = 0

        # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡
        total_days = len(portfolio_values)
        if total_days > 0 and initial_capital > 0:
            annual_return = (final_value / initial_capital) ** (365 / total_days) - 1
        else:
            annual_return = 0

        # è®¡ç®—èƒœç‡
        winning_trades = 0
        total_trades = len([t for t in trades if t[0] == 'SELL'])

        for i in range(1, len(trades)):
            if trades[i][0] == 'SELL':
                # æŸ¥æ‰¾å¯¹åº”çš„ä¹°å…¥äº¤æ˜“
                for j in range(i - 1, -1, -1):
                    if trades[j][0] == 'BUY':
                        buy_price = trades[j][2]
                        sell_price = trades[i][2]
                        if sell_price > buy_price:
                            winning_trades += 1
                        break

        win_rate = winning_trades / total_trades * 100 if total_trades > 0 else 0

        return {
            'initial_capital': initial_capital,
            'final_value': final_value,
            'total_return': total_return,
            'annual_return': annual_return * 100,
            'buy_hold_return': buy_hold_return,
            'max_drawdown': max_drawdown,
            'sharpe_ratio': sharpe_ratio,
            'win_rate': win_rate,
            'total_trades': total_trades,
            'trades': trades,
            'portfolio_values': portfolio_values,
            'dates': actual_dates[1:min(len(predictions), len(actual_dates))],
            'strategy_type': strategy_type
        }, "å›æµ‹å®Œæˆ"

    def save_model(self, filepath):
        """ä¿å­˜æ¨¡å‹å’Œé…ç½®"""
        if self.model is None:
            return False, "æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹å¯ä¿å­˜"

        # åˆ›å»ºç›®å½•
        os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)

        # ä¿å­˜æ¨¡å‹ - ä½¿ç”¨SavedModelæ ¼å¼é¿å…è‡ªå®šä¹‰å±‚é—®é¢˜
        model_path = filepath if filepath.endswith('.h5') else filepath + '.h5'

        # ä½¿ç”¨tf.saved_model.saveä¿å­˜æ•´ä¸ªæ¨¡å‹
        saved_model_dir = model_path.replace('.h5', '')
        tf.saved_model.save(self.model, saved_model_dir)

        # ä¿å­˜scalerå’Œå…¶ä»–é…ç½®
        config = {
            'time_window': self.time_window,
            'features': self.features,
            'close_idx': self.close_idx,
            'is_trained': self.is_trained,
            'model_type': self.model_type,
            'scaler_params': {
                'min_': self.scaler.min_,
                'scale_': self.scaler.scale_,
                'data_min_': self.scaler.data_min_,
                'data_max_': self.scaler.data_max_,
                'data_range_': self.scaler.data_range_
            }
        }

        config_path = filepath.replace('.h5', '_config.pkl') if filepath.endswith('.h5') else filepath + '_config.pkl'
        with open(config_path, 'wb') as f:
            pickle.dump(config, f)

        return True, f"æ¨¡å‹å·²ä¿å­˜åˆ° {saved_model_dir}"

    def load_model(self, filepath):
        """åŠ è½½æ¨¡å‹å’Œé…ç½®"""
        # å¤„ç†æ–‡ä»¶è·¯å¾„
        if filepath.endswith('.h5'):
            saved_model_dir = filepath.replace('.h5', '')
            config_path = filepath.replace('.h5', '_config.pkl')
        else:
            saved_model_dir = filepath
            config_path = filepath + '_config.pkl'

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(saved_model_dir):
            return False, f"æ¨¡å‹æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {saved_model_dir}"

        if not os.path.exists(config_path):
            return False, f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}"

        try:
            # åŠ è½½æ¨¡å‹ - ä½¿ç”¨tf.saved_model.load
            self.model = tf.saved_model.load(saved_model_dir)

            # è·å–callableçš„signatureç”¨äºé¢„æµ‹
            if hasattr(self.model, 'signatures') and 'serving_default' in self.model.signatures:
                self.model = self.model.signatures['serving_default']
            else:
                # å¦‚æœæ— æ³•è·å–serving_defaultï¼Œå°è¯•ç›´æ¥è°ƒç”¨
                self.model = self.model

            # åŠ è½½é…ç½®
            with open(config_path, 'rb') as f:
                config = pickle.load(f)

            self.time_window = config['time_window']
            self.features = config['features']
            self.close_idx = config['close_idx']
            self.is_trained = config['is_trained']
            self.model_type = config.get('model_type', 'LSTM+Attention')

            # æ¢å¤scaler
            self.scaler = MinMaxScaler(feature_range=(0, 1))
            self.scaler.min_ = config['scaler_params']['min_']
            self.scaler.scale_ = config['scaler_params']['scale_']
            self.scaler.data_min_ = config['scaler_params']['data_min_']
            self.scaler.data_max_ = config['scaler_params']['data_max_']
            self.scaler.data_range_ = config['scaler_params']['data_range_']

            return True, f"æ¨¡å‹å·²ä» {saved_model_dir} åŠ è½½"

        except Exception as e:
            return False, f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}"


# åˆå§‹åŒ–é¢„æµ‹å™¨
if 'predictor' not in st.session_state:
    st.session_state.predictor = StockPredictor()
    st.session_state.model_trained = False
    st.session_state.training_history = None

# ç•Œé¢è®¾è®¡
st.title("ğŸ“ˆ æ™ºèƒ½è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ")
st.markdown("ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œå¤šè‚¡ç¥¨è®­ç»ƒã€é¢„æµ‹å’Œé‡åŒ–å›æµ‹")

# ä¾§è¾¹æ 
st.sidebar.header("æ¨¡å‹é…ç½®")

# æ—¶é—´çª—å£è®¾ç½®
time_window = st.sidebar.slider("æ—¶é—´çª—å£å¤§å°", min_value=10, max_value=60, value=30, step=5)
st.session_state.predictor.time_window = time_window

# ä¸»ç•Œé¢é€‰é¡¹å¡
tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸš€ æ¨¡å‹è®­ç»ƒ", "ğŸ” è‚¡ç¥¨éªŒè¯", "ğŸ”® æœªæ¥é¢„æµ‹", "ğŸ“Š é‡åŒ–å›æµ‹", "ğŸ’¾ æ¨¡å‹ç®¡ç†"])

with tab1:
    st.header("æ¨¡å‹è®­ç»ƒ")

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("è®­ç»ƒå‚æ•°")

        # è‚¡ç¥¨ä»£ç è¾“å…¥
        train_stocks = st.text_area(
            "è®­ç»ƒè‚¡ç¥¨ä»£ç ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰",
            value="600519,000858,300750",
            help="ä¾‹å¦‚ï¼š600519,000858,300750"
        )

        # æ¨¡å‹é€‰æ‹©
        model_type = st.selectbox(
            "é€‰æ‹©æ¨¡å‹ç±»å‹",
            ["LSTM+Attention", "GRU", "CNN+LSTM", "Simple LSTM"],
            help="é€‰æ‹©ä¸åŒçš„ç¥ç»ç½‘ç»œæ¶æ„"
        )

        # æ¨¡å‹å‚æ•°
        col1a, col1b = st.columns(2)
        with col1a:
            lstm_units = st.slider("LSTMå•å…ƒæ•°", min_value=16, max_value=256, value=64, step=16)
            gru_units = st.slider("GRUå•å…ƒæ•°", min_value=16, max_value=256, value=64, step=16)
            attention_heads = st.slider("æ³¨æ„åŠ›å¤´æ•°", min_value=2, max_value=8, value=4, step=1)

        with col1b:
            dense_units = st.slider("å…¨è¿æ¥å±‚å•å…ƒæ•°", min_value=16, max_value=128, value=32, step=8)
            dropout_rate = st.slider("Dropoutæ¯”ç‡", min_value=0.1, max_value=0.5, value=0.2, step=0.05)
            epochs = st.number_input("è®­ç»ƒè½®æ•° (Epochs)", min_value=10, max_value=500, value=50)

        use_simulated = st.checkbox("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼ˆå½“çœŸå®æ•°æ®ä¸å¯ç”¨æ—¶ï¼‰", value=True)

    with col2:
        st.subheader("è®­ç»ƒçŠ¶æ€")
        if st.session_state.model_trained:
            st.success("âœ… æ¨¡å‹å·²è®­ç»ƒå®Œæˆ")
            if st.session_state.training_history:
                st.write(f"æ¨¡å‹ç±»å‹: {st.session_state.predictor.model_type}")
                st.write(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {st.session_state.training_history.history['loss'][-1]:.4f}")
                st.write(f"æœ€ç»ˆéªŒè¯æŸå¤±: {st.session_state.training_history.history['val_loss'][-1]:.4f}")
        else:
            st.warning("â³ æ¨¡å‹æœªè®­ç»ƒ")

        # è®­ç»ƒè¿›åº¦åŒºåŸŸ
        progress_bar = st.progress(0)
        status_text = st.empty()

    if st.button("å¼€å§‹è®­ç»ƒæ¨¡å‹", type="primary"):
        if train_stocks.strip():
            stock_list = [s.strip() for s in train_stocks.split(',') if s.strip()]

            st.info(f"å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨ {len(stock_list)} åªè‚¡ç¥¨æ•°æ®")

            with st.spinner("æ­£åœ¨è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç¨å€™..."):
                history, train_X, train_y, test_X, test_y, stock_info = st.session_state.predictor.train_model(
                    stock_list,
                    epochs=epochs,
                    use_simulated=use_simulated,
                    model_type=model_type,
                    lstm_units=lstm_units,
                    gru_units=gru_units,
                    attention_heads=attention_heads,
                    dense_units=dense_units,
                    dropout_rate=dropout_rate,
                    progress_bar=progress_bar,
                    status_text=status_text
                )

                st.session_state.training_history = history
                st.session_state.model_trained = True

                # æ˜¾ç¤ºè®­ç»ƒç»“æœ
                st.success("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

                # æ˜¾ç¤ºè‚¡ç¥¨æ•°æ®ä¿¡æ¯
                st.subheader("è®­ç»ƒæ•°æ®ä¿¡æ¯")
                for info in stock_info:
                    st.write(f"- {info}")

                # ç»˜åˆ¶è®­ç»ƒå†å²
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

                ax1.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±')
                ax1.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±')
                ax1.set_title('æ¨¡å‹æŸå¤±')
                ax1.set_xlabel('Epoch')
                ax1.set_ylabel('Loss')
                ax1.legend()
                ax1.grid(True, alpha=0.3)

                ax2.plot(history.history['mae'], label='è®­ç»ƒMAE')
                ax2.plot(history.history['val_mae'], label='éªŒè¯MAE')
                ax2.set_title('æ¨¡å‹MAE')
                ax2.set_xlabel('Epoch')
                ax2.set_ylabel('MAE')
                ax2.legend()
                ax2.grid(True, alpha=0.3)

                st.pyplot(fig)

        else:
            st.error("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè‚¡ç¥¨ä»£ç ")

with tab2:
    st.header("è‚¡ç¥¨éªŒè¯")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("éªŒè¯å‚æ•°")
        validate_stock = st.text_input("éªŒè¯è‚¡ç¥¨ä»£ç ", value="000001")
        use_current_model = st.checkbox("ä½¿ç”¨å½“å‰è®­ç»ƒå¥½çš„æ¨¡å‹", value=True)

    with col2:
        st.subheader("éªŒè¯è¯´æ˜")
        st.info("""
        ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æ–°çš„è‚¡ç¥¨æ•°æ®è¿›è¡ŒéªŒè¯ï¼Œ
        è¯„ä¼°æ¨¡å‹åœ¨æœªè§è¿‡çš„è‚¡ç¥¨ä¸Šçš„è¡¨ç°ã€‚
        """)

    if st.button("å¼€å§‹éªŒè¯", type="primary"):
        if validate_stock.strip() and st.session_state.model_trained:
            with st.spinner("æ­£åœ¨éªŒè¯æ¨¡å‹..."):
                # è·å–éªŒè¯æ•°æ®
                data, info = st.session_state.predictor.get_stock_data(validate_stock)
                if data is None:
                    st.error(f"æ— æ³•è·å–è‚¡ç¥¨ {validate_stock} çš„æ•°æ®")
                else:
                    st.success(info)

                    # è¿›è¡Œé¢„æµ‹
                    predictions, true_values = st.session_state.predictor.predict(data)

                    if predictions is not None:
                        # è¯„ä¼°æ¨¡å‹
                        metrics = st.session_state.predictor.evaluate_model(true_values, predictions)

                        # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
                        st.subheader("éªŒè¯ç»“æœ")
                        col1, col2, col3, col4 = st.columns(4)
                        col1.metric("MAE", f"{metrics['MAE']:.4f}")
                        col2.metric("RMSE", f"{metrics['RMSE']:.4f}")
                        col3.metric("RÂ² Score", f"{metrics['R2']:.4f}")
                        col4.metric("æ–¹å‘å‡†ç¡®ç‡", f"{metrics['Direction_Accuracy']:.2f}%")

                        # ç»˜åˆ¶éªŒè¯ç»“æœ
                        train_size = int(len(data) * 0.8)
                        test_dates = data.index[train_size + time_window:]

                        fig = go.Figure()
                        fig.add_trace(go.Scatter(
                            x=test_dates, y=true_values,
                            mode='lines', name='çœŸå®ä»·æ ¼',
                            line=dict(color='blue', width=2)
                        ))
                        fig.add_trace(go.Scatter(
                            x=test_dates, y=predictions,
                            mode='lines', name='é¢„æµ‹ä»·æ ¼',
                            line=dict(color='red', width=1, dash='dash')
                        ))
                        fig.update_layout(
                            title=f'{validate_stock} éªŒè¯ç»“æœ',
                            xaxis_title='æ—¥æœŸ',
                            yaxis_title='ä»·æ ¼ï¼ˆå…ƒï¼‰',
                            hovermode='x unified'
                        )
                        st.plotly_chart(fig, use_container_width=True)
        else:
            st.error("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–è¾“å…¥è‚¡ç¥¨ä»£ç ")

with tab3:
    st.header("æœªæ¥é¢„æµ‹")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("é¢„æµ‹å‚æ•°")
        predict_stock = st.text_input("é¢„æµ‹è‚¡ç¥¨ä»£ç ", value="600519")
        predict_days = st.slider("é¢„æµ‹å¤©æ•°", min_value=5, max_value=60, value=30)
        end_date = st.date_input("æ•°æ®æˆªæ­¢æ—¥æœŸ", value=datetime.now())

    with col2:
        st.subheader("é¢„æµ‹è¯´æ˜")
        st.info("""
        åŸºäºå†å²æ•°æ®é¢„æµ‹æœªæ¥è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿ã€‚
        é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚
        """)

    if st.button("å¼€å§‹é¢„æµ‹", type="primary"):
        if predict_stock.strip() and st.session_state.model_trained:
            with st.spinner("æ­£åœ¨è¿›è¡Œé¢„æµ‹..."):
                # è·å–æ•°æ®
                end_date_str = end_date.strftime("%Y%m%d")
                data, info = st.session_state.predictor.get_stock_data(predict_stock, end_date=end_date_str)

                if data is None:
                    st.error(f"æ— æ³•è·å–è‚¡ç¥¨ {predict_stock} çš„æ•°æ®")
                else:
                    st.success(info)

                    # è¿›è¡Œæœªæ¥é¢„æµ‹
                    future_predictions = st.session_state.predictor.predict_future(data, days=predict_days)

                    if future_predictions is not None:
                        # åˆ›å»ºæœªæ¥æ—¥æœŸ
                        last_date = data.index[-1]
                        future_dates = [last_date + timedelta(days=i) for i in range(1, predict_days + 1)]

                        # ç»˜åˆ¶é¢„æµ‹ç»“æœ
                        fig = make_subplots(rows=2, cols=1, subplot_titles=('å®Œæ•´è§†å›¾', 'é¢„æµ‹è¯¦æƒ…'))

                        # å†å²æ•°æ®ï¼ˆæœ€è¿‘180å¤©ï¼‰
                        recent_data = data.tail(180)
                        fig.add_trace(go.Scatter(
                            x=recent_data.index, y=recent_data['æ”¶ç›˜'],
                            mode='lines', name='å†å²ä»·æ ¼',
                            line=dict(color='blue', width=2)
                        ), row=1, col=1)

                        # æœªæ¥é¢„æµ‹
                        fig.add_trace(go.Scatter(
                            x=future_dates, y=future_predictions,
                            mode='lines+markers', name='æœªæ¥é¢„æµ‹',
                            line=dict(color='red', width=2, dash='dash')
                        ), row=1, col=1)

                        fig.add_vline(x=last_date, line_dash="dash", line_color="gray", row=1, col=1)

                        # é¢„æµ‹è¯¦æƒ…
                        fig.add_trace(go.Scatter(
                            x=future_dates, y=future_predictions,
                            mode='lines+markers+text', name='é¢„æµ‹ä»·æ ¼',
                            line=dict(color='red', width=3),
                            text=[f'{price:.2f}' for price in future_predictions],
                            textposition="top center"
                        ), row=2, col=1)

                        fig.update_layout(
                            title=f'{predict_stock} æœªæ¥{predict_days}å¤©ä»·æ ¼é¢„æµ‹',
                            height=600,
                            showlegend=True
                        )

                        fig.update_xaxes(title_text="æ—¥æœŸ", row=2, col=1)
                        fig.update_yaxes(title_text="ä»·æ ¼ï¼ˆå…ƒï¼‰", row=1, col=1)
                        fig.update_yaxes(title_text="ä»·æ ¼ï¼ˆå…ƒï¼‰", row=2, col=1)

                        st.plotly_chart(fig, use_container_width=True)

                        # æ˜¾ç¤ºé¢„æµ‹æ•°æ®è¡¨
                        st.subheader("é¢„æµ‹æ•°æ®")
                        prediction_df = pd.DataFrame({
                            'æ—¥æœŸ': future_dates,
                            'é¢„æµ‹ä»·æ ¼': future_predictions
                        })
                        st.dataframe(prediction_df.style.format({'é¢„æµ‹ä»·æ ¼': '{:.2f}'}))
        else:
            st.error("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–è¾“å…¥è‚¡ç¥¨ä»£ç ")

with tab4:
    st.header("é‡åŒ–ç­–ç•¥å›æµ‹")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("å›æµ‹å‚æ•°")
        backtest_stock = st.text_input("å›æµ‹è‚¡ç¥¨ä»£ç ", value="000001")

        # ç­–ç•¥é€‰æ‹©
        strategy_type = st.selectbox(
            "é€‰æ‹©å›æµ‹ç­–ç•¥",
            ["simple", "rsi_based", "ma_crossover", "combined", "momentum"],
            format_func=lambda x: {
                "simple": "ç®€å•é¢„æµ‹ç­–ç•¥",
                "rsi_based": "RSIç­–ç•¥",
                "ma_crossover": "ç§»åŠ¨å¹³å‡çº¿ç­–ç•¥",
                "combined": "ç»¼åˆç­–ç•¥",
                "momentum": "åŠ¨é‡ç­–ç•¥"
            }[x]
        )

        initial_capital = st.number_input("åˆå§‹èµ„é‡‘ï¼ˆå…ƒï¼‰", min_value=10000, max_value=1000000, value=100000, step=10000)
        transaction_cost = st.slider("äº¤æ˜“æˆæœ¬ï¼ˆ%ï¼‰", min_value=0.0, max_value=0.5, value=0.1, step=0.05) / 100

        # ç­–ç•¥ç‰¹å®šå‚æ•°
        if strategy_type in ["rsi_based", "combined"]:
            col1a, col1b = st.columns(2)
            with col1a:
                rsi_oversold = st.slider("RSIè¶…å–çº¿", min_value=10, max_value=40, value=30)
            with col1b:
                rsi_overbought = st.slider("RSIè¶…ä¹°çº¿", min_value=60, max_value=90, value=70)

        if strategy_type in ["ma_crossover", "combined"]:
            col2a, col2b = st.columns(2)
            with col2a:
                ma_short = st.slider("çŸ­æœŸå‡çº¿", min_value=3, max_value=20, value=5)
            with col2b:
                ma_long = st.slider("é•¿æœŸå‡çº¿", min_value=10, max_value=50, value=20)

        # é£é™©æ§åˆ¶å‚æ•°
        col3a, col3b = st.columns(2)
        with col3a:
            stop_loss = st.slider("æ­¢æŸæ¯”ä¾‹ï¼ˆ%ï¼‰", min_value=1.0, max_value=20.0, value=5.0, step=0.5) / 100
        with col3b:
            take_profit = st.slider("æ­¢ç›ˆæ¯”ä¾‹ï¼ˆ%ï¼‰", min_value=5.0, max_value=50.0, value=10.0, step=1.0) / 100

    with col2:
        st.subheader("ç­–ç•¥è¯´æ˜")
        strategy_descriptions = {
            "simple": "åŸºäºé¢„æµ‹ä»·æ ¼æ–¹å‘è¿›è¡Œä¹°å–çš„ç®€å•ç­–ç•¥",
            "rsi_based": "ç»“åˆRSIè¶…ä¹°è¶…å–å’Œé¢„æµ‹ä¿¡å·çš„ç­–ç•¥",
            "ma_crossover": "åŸºäºç§»åŠ¨å¹³å‡çº¿äº¤å‰å’Œé¢„æµ‹ä¿¡å·çš„ç­–ç•¥",
            "combined": "ç»¼åˆå¤šç§æŠ€æœ¯æŒ‡æ ‡å’Œé¢„æµ‹ä¿¡å·çš„ç­–ç•¥",
            "momentum": "åŸºäºä»·æ ¼åŠ¨é‡å’Œé¢„æµ‹ä¿¡å·çš„ç­–ç•¥"
        }
        st.info(strategy_descriptions.get(strategy_type, ""))

        st.subheader("é£é™©æç¤º")
        st.warning("""
        - å›æµ‹ç»“æœåŸºäºå†å²æ•°æ®ï¼Œä¸ä»£è¡¨æœªæ¥è¡¨ç°
        - å®é™…äº¤æ˜“ä¸­åº”è€ƒè™‘æ›´å¤šå› ç´ 
        - æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…
        """)

    if st.button("å¼€å§‹å›æµ‹", type="primary"):
        if backtest_stock.strip() and st.session_state.model_trained:
            with st.spinner("æ­£åœ¨è¿›è¡Œå›æµ‹..."):
                # è·å–æ•°æ®
                data, info = st.session_state.predictor.get_stock_data(backtest_stock)
                if data is None:
                    st.error(f"æ— æ³•è·å–è‚¡ç¥¨ {backtest_stock} çš„æ•°æ®")
                else:
                    st.success(info)

                    # è¿›è¡Œé¢„æµ‹
                    predictions, true_values = st.session_state.predictor.predict(data)

                    if predictions is not None:
                        # æ‰§è¡Œå›æµ‹
                        backtest_result, message = st.session_state.predictor.backtest_strategy(
                            data, predictions, strategy_type, initial_capital, transaction_cost,
                            rsi_oversold, rsi_overbought, ma_short, ma_long, stop_loss, take_profit
                        )

                        if backtest_result:
                            st.success(message)

                            # æ˜¾ç¤ºå›æµ‹ç»“æœ
                            st.subheader("å›æµ‹ç»“æœ")

                            col1, col2, col3, col4 = st.columns(4)
                            col1.metric("ç­–ç•¥æ€»æ”¶ç›Š", f"{backtest_result['total_return']:.2f}%")
                            col2.metric("å¹´åŒ–æ”¶ç›Š", f"{backtest_result['annual_return']:.2f}%")
                            col3.metric("ä¹°å…¥æŒæœ‰æ”¶ç›Š", f"{backtest_result['buy_hold_return']:.2f}%")
                            col4.metric("èƒœç‡", f"{backtest_result['win_rate']:.2f}%")

                            col1, col2, col3, col4 = st.columns(4)
                            col1.metric("æœ€å¤§å›æ’¤", f"{backtest_result['max_drawdown']:.2f}%")
                            col2.metric("å¤æ™®æ¯”ç‡", f"{backtest_result['sharpe_ratio']:.2f}")
                            col3.metric("äº¤æ˜“æ¬¡æ•°", f"{backtest_result['total_trades']}")
                            strategy_name = {
                                "simple": "ç®€å•é¢„æµ‹",
                                "rsi_based": "RSIç­–ç•¥",
                                "ma_crossover": "å‡çº¿ç­–ç•¥",
                                "combined": "ç»¼åˆç­–ç•¥",
                                "momentum": "åŠ¨é‡ç­–ç•¥"
                            }.get(backtest_result['strategy_type'], backtest_result['strategy_type'])
                            col4.metric("ç­–ç•¥ç±»å‹", strategy_name)

                            # ç»˜åˆ¶å›æµ‹ç»“æœ
                            if len(backtest_result['dates']) > 0 and len(backtest_result['portfolio_values']) > 0:
                                fig = go.Figure()

                                # ç­–ç•¥å‡€å€¼æ›²çº¿
                                fig.add_trace(go.Scatter(
                                    x=backtest_result['dates'],
                                    y=backtest_result['portfolio_values'],
                                    mode='lines',
                                    name='ç­–ç•¥å‡€å€¼',
                                    line=dict(color='blue', width=2)
                                ))

                                # ä¹°å…¥æŒæœ‰å‡€å€¼æ›²çº¿
                                buy_hold_values = [initial_capital * (
                                            1 + backtest_result['buy_hold_return'] / 100 * i / len(
                                        backtest_result['dates']))
                                                   for i in range(len(backtest_result['dates']))]
                                fig.add_trace(go.Scatter(
                                    x=backtest_result['dates'],
                                    y=buy_hold_values,
                                    mode='lines',
                                    name='ä¹°å…¥æŒæœ‰',
                                    line=dict(color='green', width=2, dash='dash')
                                ))

                                # æ ‡è®°äº¤æ˜“ç‚¹
                                buy_dates = []
                                buy_prices = []
                                sell_dates = []
                                sell_prices = []

                                for trade in backtest_result['trades']:
                                    if trade[0] == 'BUY':
                                        buy_dates.append(trade[1])
                                        buy_prices.append(trade[2])
                                    elif trade[0] == 'SELL':
                                        sell_dates.append(trade[1])
                                        sell_prices.append(trade[2])

                                if buy_dates:
                                    fig.add_trace(go.Scatter(
                                        x=buy_dates,
                                        y=buy_prices,
                                        mode='markers',
                                        name='ä¹°å…¥ç‚¹',
                                        marker=dict(color='green', size=10, symbol='triangle-up')
                                    ))

                                if sell_dates:
                                    fig.add_trace(go.Scatter(
                                        x=sell_dates,
                                        y=sell_prices,
                                        mode='markers',
                                        name='å–å‡ºç‚¹',
                                        marker=dict(color='red', size=10, symbol='triangle-down')
                                    ))

                                fig.update_layout(
                                    title=f'{backtest_stock} {strategy_name}å›æµ‹ç»“æœ',
                                    xaxis_title='æ—¥æœŸ',
                                    yaxis_title='æŠ•èµ„ç»„åˆä»·å€¼ï¼ˆå…ƒï¼‰',
                                    hovermode='x unified',
                                    height=500
                                )

                                st.plotly_chart(fig, use_container_width=True)

                                # æ˜¾ç¤ºæŠ€æœ¯æŒ‡æ ‡å›¾è¡¨
                                st.subheader("æŠ€æœ¯æŒ‡æ ‡")
                                tech_fig = make_subplots(rows=2, cols=1, subplot_titles=('ä»·æ ¼ä¸å‡çº¿', 'RSIæŒ‡æ ‡'))

                                # ä»·æ ¼å’Œå‡çº¿
                                tech_fig.add_trace(go.Scatter(
                                    x=data.index,
                                    y=data['æ”¶ç›˜'],
                                    mode='lines',
                                    name='æ”¶ç›˜ä»·',
                                    line=dict(color='black', width=1)
                                ), row=1, col=1)

                                if 'MA5' in data.columns:
                                    tech_fig.add_trace(go.Scatter(
                                        x=data.index,
                                        y=data['MA5'],
                                        mode='lines',
                                        name='MA5',
                                        line=dict(color='blue', width=1)
                                    ), row=1, col=1)

                                if 'MA20' in data.columns:
                                    tech_fig.add_trace(go.Scatter(
                                        x=data.index,
                                        y=data['MA20'],
                                        mode='lines',
                                        name='MA20',
                                        line=dict(color='red', width=1)
                                    ), row=1, col=1)

                                # RSI
                                if 'RSI' in data.columns:
                                    tech_fig.add_trace(go.Scatter(
                                        x=data.index,
                                        y=data['RSI'],
                                        mode='lines',
                                        name='RSI',
                                        line=dict(color='purple', width=1)
                                    ), row=2, col=1)

                                    # æ·»åŠ è¶…ä¹°è¶…å–çº¿
                                    tech_fig.add_hline(y=70, line_dash="dash", line_color="red", row=2, col=1)
                                    tech_fig.add_hline(y=30, line_dash="dash", line_color="green", row=2, col=1)

                                tech_fig.update_layout(height=600, showlegend=True)
                                tech_fig.update_yaxes(title_text="ä»·æ ¼", row=1, col=1)
                                tech_fig.update_yaxes(title_text="RSI", row=2, col=1)

                                st.plotly_chart(tech_fig, use_container_width=True)
                            else:
                                st.warning("å›æµ‹æ•°æ®ä¸è¶³ï¼Œæ— æ³•ç»˜åˆ¶å›¾è¡¨")

                            # æ˜¾ç¤ºäº¤æ˜“è®°å½•
                            if backtest_result['trades']:
                                st.subheader("äº¤æ˜“è®°å½•")
                                trades_df = pd.DataFrame(backtest_result['trades'],
                                                         columns=['æ“ä½œ', 'æ—¥æœŸ', 'ä»·æ ¼', 'å¤‡æ³¨'])
                                st.dataframe(trades_df.style.format({'ä»·æ ¼': '{:.2f}'}))
                        else:
                            st.error(message)
        else:
            st.error("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–è¾“å…¥è‚¡ç¥¨ä»£ç ")

with tab5:
    st.header("æ¨¡å‹ç®¡ç†")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ä¿å­˜æ¨¡å‹")
        save_path = st.text_input("æ¨¡å‹ä¿å­˜è·¯å¾„", value="saved_models/stock_predictor",
                                  help="è¯·è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¾‹å¦‚: saved_models/my_model")

        st.info("""
        **ä¿å­˜è¯´æ˜:**
        - æ¨¡å‹å°†ä¿å­˜ä¸ºä¸€ä¸ªæ–‡ä»¶å¤¹å’Œä¸€ä¸ªé…ç½®æ–‡ä»¶
        - ä¾‹å¦‚: è¾“å…¥ `saved_models/my_model` å°†åˆ›å»º:
          - `saved_models/my_model/` (æ¨¡å‹æ–‡ä»¶å¤¹)
          - `saved_models/my_model_config.pkl` (é…ç½®æ–‡ä»¶)
        """)

        if st.button("ä¿å­˜æ¨¡å‹", type="primary"):
            if st.session_state.model_trained:
                success, message = st.session_state.predictor.save_model(save_path)
                if success:
                    st.success(message)
                else:
                    st.error(message)
            else:
                st.error("æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹å¯ä¿å­˜")

    with col2:
        st.subheader("åŠ è½½æ¨¡å‹")
        load_path = st.text_input("æ¨¡å‹åŠ è½½è·¯å¾„", value="saved_models/stock_predictor",
                                  help="è¯·è¾“å…¥æ¨¡å‹æ–‡ä»¶å¤¹è·¯å¾„ï¼Œä¾‹å¦‚: saved_models/my_model")

        st.info("""
        **åŠ è½½è¯´æ˜:**
        - è¯·è¾“å…¥æ¨¡å‹æ–‡ä»¶å¤¹çš„è·¯å¾„
        - ä¾‹å¦‚: è¾“å…¥ `saved_models/my_model` å°†åŠ è½½:
          - `saved_models/my_model/` (æ¨¡å‹æ–‡ä»¶å¤¹)
          - `saved_models/my_model_config.pkl` (é…ç½®æ–‡ä»¶)
        - è¯·ç¡®ä¿è¿™ä¸¤ä¸ªæ–‡ä»¶éƒ½å­˜åœ¨
        """)

        # æ˜¾ç¤ºå½“å‰ç›®å½•ä¸‹çš„æ¨¡å‹æ–‡ä»¶
        if st.button("æŸ¥çœ‹å¯ç”¨æ¨¡å‹"):
            model_dirs = []
            if os.path.exists("saved_models"):
                for item in os.listdir("saved_models"):
                    item_path = os.path.join("saved_models", item)
                    if os.path.isdir(item_path):
                        config_file = os.path.join("saved_models", f"{item}_config.pkl")
                        if os.path.exists(config_file):
                            model_dirs.append(item)

            if model_dirs:
                st.write("å¯ç”¨çš„æ¨¡å‹:")
                for model_dir in model_dirs:
                    st.write(f"- saved_models/{model_dir}")
            else:
                st.write("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹")

        if st.button("åŠ è½½æ¨¡å‹", type="primary"):
            success, message = st.session_state.predictor.load_model(load_path)
            if success:
                st.session_state.model_trained = True
                st.success(message)
            else:
                st.error(message)

    # æ¨¡å‹ä¿¡æ¯
    st.subheader("æ¨¡å‹ä¿¡æ¯")
    if st.session_state.model_trained:
        st.success("âœ… æ¨¡å‹å·²åŠ è½½")
        st.write(f"- æ¨¡å‹ç±»å‹: {st.session_state.predictor.model_type}")
        st.write(f"- æ—¶é—´çª—å£: {st.session_state.predictor.time_window}å¤©")
        st.write(f"- è¾“å…¥ç‰¹å¾: {', '.join(st.session_state.predictor.features)}")
        if st.session_state.training_history:
            st.write(f"- æœ€ç»ˆè®­ç»ƒæŸå¤±: {st.session_state.training_history.history['loss'][-1]:.4f}")
            st.write(f"- æœ€ç»ˆéªŒè¯æŸå¤±: {st.session_state.training_history.history['val_loss'][-1]:.4f}")
    else:
        st.warning("â³ æ¨¡å‹æœªåŠ è½½")

    # æ•°æ®ç¼“å­˜ç®¡ç†
    st.subheader("æ•°æ®ç¼“å­˜ç®¡ç†")
    if st.button("æ¸…é™¤æ•°æ®ç¼“å­˜"):
        cache_dir = "stock_data_cache"
        if os.path.exists(cache_dir):
            for file in os.listdir(cache_dir):
                file_path = os.path.join(cache_dir, file)
                try:
                    if os.path.isfile(file_path):
                        os.unlink(file_path)
                except Exception as e:
                    st.error(f"åˆ é™¤æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            st.success("æ•°æ®ç¼“å­˜å·²æ¸…é™¤")
        else:
            st.info("æ•°æ®ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")

# é¡µè„š
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>ğŸ“Š æ™ºèƒ½è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ | åŸºäºæ·±åº¦å­¦ä¹ çš„æ—¶é—´åºåˆ—é¢„æµ‹ä¸é‡åŒ–å›æµ‹</p>
        <p><small>æ³¨æ„ï¼šæœ¬ç³»ç»Ÿé¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚</small></p>
    </div>
    """,
    unsafe_allow_html=True
)
